{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjIG882ZoyVl"
      },
      "source": [
        "Simple example of eXirt's use"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run all bullets in the sequence below!"
      ],
      "metadata": {
        "id": "7Pzk_smLpiUR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM_sX-w4IcIJ"
      },
      "source": [
        "\n",
        "\n",
        "Generate files?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYRB58lNnHAX"
      },
      "source": [
        "## Install dependences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openml\n",
        "!pip install catsim\n",
        "\n",
        "import openml\n",
        "import pandas as pd\n",
        "import statistics\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn import metrics\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "!wget https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_OtML.py\n",
        "!wget https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_MLtIRT.py\n",
        "!wget https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_analysis.py\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySk3bH_Vm1Cn",
        "outputId": "78766c3c-5ff4-45c0-96ee-6e589e20ff93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openml\n",
            "  Downloading openml-0.13.0-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from openml) (1.3.5)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.8/dist-packages (from openml) (1.7.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from openml) (2.25.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from openml) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from openml) (2.8.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.8/dist-packages (from openml) (9.0.0)\n",
            "Requirement already satisfied: numpy>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from openml) (1.21.6)\n",
            "Collecting minio\n",
            "  Downloading minio-7.1.13-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 KB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting liac-arff>=2.4.0\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.0->openml) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil->openml) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->openml) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->openml) (1.2.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from minio->openml) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from minio->openml) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->openml) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->openml) (4.0.0)\n",
            "Building wheels for collected packages: liac-arff\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11732 sha256=5823b25509301ccb0938b73f31ca2b7858f14e743679a0cfc4051ca0d0b0cf74\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/de/68/bf3972de3ecb31e32bef59a7f4c75f0687a3674c476b347c14\n",
            "Successfully built liac-arff\n",
            "Installing collected packages: xmltodict, minio, liac-arff, openml\n",
            "Successfully installed liac-arff-2.5.0 minio-7.1.13 openml-0.13.0 xmltodict-0.13.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: catsim in /usr/local/lib/python3.8/dist-packages (0.17.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from catsim) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from catsim) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from catsim) (4.64.1)\n",
            "Requirement already satisfied: json-tricks in /usr/local/lib/python3.8/dist-packages (from catsim) (3.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from catsim) (1.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from catsim) (3.2.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.8/dist-packages (from catsim) (2.8.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catsim) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catsim) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catsim) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catsim) (3.0.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->catsim) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->catsim) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->catsim) (1.15.0)\n",
            "--2023-01-10 12:47:05--  https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_OtML.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19052 (19K) [text/plain]\n",
            "Saving to: ‘decodIRT_OtML.py’\n",
            "\n",
            "decodIRT_OtML.py    100%[===================>]  18.61K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-10 12:47:05 (66.0 MB/s) - ‘decodIRT_OtML.py’ saved [19052/19052]\n",
            "\n",
            "--2023-01-10 12:47:05--  https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_MLtIRT.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7453 (7.3K) [text/plain]\n",
            "Saving to: ‘decodIRT_MLtIRT.py’\n",
            "\n",
            "decodIRT_MLtIRT.py  100%[===================>]   7.28K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-10 12:47:06 (46.0 MB/s) - ‘decodIRT_MLtIRT.py’ saved [7453/7453]\n",
            "\n",
            "--2023-01-10 12:47:06--  https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_analysis.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33818 (33K) [text/plain]\n",
            "Saving to: ‘decodIRT_analysis.py’\n",
            "\n",
            "decodIRT_analysis.p 100%[===================>]  33.03K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-01-10 12:47:08 (19.3 MB/s) - ‘decodIRT_analysis.py’ saved [33818/33818]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQcwXWF97TrR"
      },
      "source": [
        "## eXirt tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "0Pvq-euegHVF"
      },
      "outputs": [],
      "source": [
        "class EXirt():\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def dirByDataset(self, datasetName):\n",
        "      !mkdir $self.path_content$self.path_fig$datasetName\n",
        "      !mkdir $self.path_content$self.path_csv$datasetName\n",
        "      !mkdir $self.path_content$self.path_model$datasetName\n",
        "      !mkdir $self.path_content$self.path_irt$datasetName\n",
        "\n",
        "  def __init__(self):\n",
        "    ############################## PATH FILE ###################################\n",
        "    self.do_download = True\n",
        "\n",
        "    self.path_content = '/content'\n",
        "    self.path_fig = '/out_fig'\n",
        "    self.path_csv = '/out_csv'\n",
        "    self.path_model = '/out_model'\n",
        "    self.path_irt = '/out_irt' \n",
        "    self.path_dataset = '/*'\n",
        "\n",
        "    !rm -r $self.path_content$self.path_fig\n",
        "    !rm -r $self.path_content$self.path_csv\n",
        "    !rm -r $self.path_content$self.path_model\n",
        "    !rm -r $self.path_content$self.path_irt\n",
        "\n",
        "\n",
        "    !mkdir $self.path_content$self.path_fig\n",
        "    !mkdir $self.path_content$self.path_csv\n",
        "    !mkdir $self.path_content$self.path_model\n",
        "    !mkdir $self.path_content$self.path_irt\n",
        "\n",
        "    self.path_dataset = ''\n",
        "    ############################## GENERAL CONTROL #############################\n",
        "    self.proposal_1_pool = 1\n",
        "    self.proposal_2_loop = 2\n",
        "    self.exec_proposal = self.proposal_2_loop\n",
        "\n",
        "    # verbose\n",
        "    self.verbose = False\n",
        "    self.verbose_graph = False\n",
        "\n",
        "    self.download_files = True\n",
        "\n",
        "    # performance\n",
        "    self.exec_accuracy = 1\n",
        "    self.exec_auc = 2\n",
        "    self.exec_performance = self.exec_accuracy\n",
        "    self.normalize_performance = True\n",
        "\n",
        "    ################################### IRT ####################################\n",
        "    #execute theta ou trueScore\n",
        "    self.exec_theta = 0\n",
        "    self.exec_trueScore = 1\n",
        "    self.exec_base_irt_score = self.exec_trueScore\n",
        "\n",
        "    # calculo de  theta\n",
        "    self.theta_sum = 0\n",
        "    self.theta_min = 1\n",
        "    self.theta_mean = 2\n",
        "    self.exec_calc_theta = self.theta_mean\n",
        "\n",
        "\n",
        "    # irt algorithm ‘ternary’, ‘dichotomous’, ‘fibonacci’, ‘golden’, ‘brent’, ‘bounded’ and ‘golden2’\n",
        "    self.irt_method_fibonacci = '-metodo fibonacci'\n",
        "    self.irt_method_bounded = '-metodo bounded'\n",
        "    self.irt_method_ternary = '-metodo ternary' #long time execution\n",
        "    self.irt_method_dichotomous = '-metodo dichotomous' #long time execution\n",
        "    self.irt_method_golden = '-metodo golden'\n",
        "    self.irt_method_brent = '-metodo brent'\n",
        "    self.irt_method_golden2 = '-metodo golden2' #problem in execution\n",
        "    self.irt_method = self.irt_method_bounded\n",
        "\n",
        "    # Properties of IRT\n",
        "    self.irt_discriminate = True #False remove the property by IRTs calc.\n",
        "    self.irt_difficulty = True #False remove the property by IRTs calc.\n",
        "    self.irt_divine = True #False remove the property by IRTs calc.\n",
        "\n",
        "    ################################## PROPOSAL 1 POOL #########################\n",
        "    self.include_original_clf_data_pool = True\n",
        "    self.number_of_features_deletion = 2 # values 1 to ++\n",
        "\n",
        "    self.list_clf_pool = [] #empity\n",
        "\n",
        "    ################################## PROPOSAL 2 LOOP #########################\n",
        "\n",
        "    self.include_original_clf_data_loop = True\n",
        "    self.number_of_features_variation = 2 # values 1 to 4\n",
        "\n",
        "    # test or train\n",
        "    self.exec_test = 0\n",
        "    self.exec_train = 1\n",
        "    self.exec_in = self.exec_test\n",
        "\n",
        "    #loop of models variation\n",
        "    self.exec_permutation = 0 # random base\n",
        "    self.exec_noise = 1 # random base\n",
        "    self.exec_zeros = 2\n",
        "    self.exec_norm = 3 \n",
        "    self.exec_ordup = 4\n",
        "    self.exec_orddown = 5\n",
        "    self.exec_inver = 6\n",
        "    self.exec_binning = 7\n",
        "    self.exec_mult_neg = 8\n",
        "    self.exec_mean = 9\n",
        "    self.exec_std = 10\n",
        "    self.exec_zscore = 11\n",
        "    self.exec_variation_method = [self.exec_mult_neg, self.exec_binning]\n",
        "\n",
        "    #list of thetas\n",
        "    self.list_clf_loop = [] #empity\n",
        "\n",
        "  ########################## Global declaration ################################\n",
        "\n",
        "  def z_score_serie(self, s):\n",
        "    # copy the dataframe\n",
        "    s_std = s.copy()\n",
        "    s_std = (s_std - s_std.mean()) / s_std.std()\n",
        "    return s_std\n",
        "\n",
        "  def auc_score(self, y, y_pred):\n",
        "      \n",
        "      fpr, tpr, thresholds = metrics.roc_curve(y, y_pred, pos_label=2)\n",
        "      \n",
        "      return metrics.auc(fpr, tpr)\n",
        "\n",
        "  def powerSetLimited(self, s,l):\n",
        "\n",
        "      def powerset(s):\n",
        "        x = len(s)\n",
        "        masks = [1 << i for i in range(x)]\n",
        "        for i in range(1 << x):\n",
        "            yield [ss for mask, ss in zip(masks, s) if i & mask]\n",
        "      \n",
        "      psl = []\n",
        "      ps = list(powerset(s))\n",
        "      for _,i in enumerate(ps):\n",
        "        if len(i) <= l and len(i)>0:\n",
        "          psl.append(i)\n",
        "      return psl\n",
        "\n",
        "  def run_prepare(self, model,data_exec_x, data_exec_y, X_train, X_test, y_train, y_test):\n",
        "    %rm $self.path_content$self.path_irt'/tabela_base_para_executar_irt.csv'\n",
        "    %rm $self.path_content$self.path_irt'/tabela_base_para_executar_irt_accuracy.csv'\n",
        "\n",
        "\n",
        "    #prediction\n",
        "    original_outputs = model.predict(data_exec_x)\n",
        "\n",
        "\n",
        "    #XAI-IRT\n",
        "    # train, test, model and outputs\n",
        "\n",
        "    #Loop of models\n",
        "    df_loop_of_models = pd.DataFrame()\n",
        "    \n",
        "    #Prepare df_loop_of_models\n",
        "    #df_loop_of_models['Clf'] = [] \n",
        "    #for i in range(len(data_exec_y)):\n",
        "    #  df_loop_of_models['V'+str(i)] = []\n",
        "    \n",
        "    list_col_tmp = ['Clf']\n",
        "    for i in range(len(data_exec_y)):\n",
        "      list_col_tmp.append('V'+str(i))\n",
        "    df_loop_of_models = pd.DataFrame(columns=list_col_tmp)\n",
        "\n",
        "    df_loop_of_models_performance = pd.DataFrame(columns=['Metodo','Acuracia'])\n",
        "\n",
        "\n",
        "\n",
        "    if self.exec_proposal == self.proposal_2_loop:\n",
        "      if self.verbose:\n",
        "        print('Original data')\n",
        "        print(data_exec_x)\n",
        "\n",
        "      number_of_instances = len(data_exec_x)\n",
        "\n",
        "      if self.include_original_clf_data_loop:\n",
        "        str_tmp = 'Clf original data'\n",
        "        if self.exec_performance == self.exec_accuracy:\n",
        "          result_accuracy = accuracy_score(y_true = original_outputs, y_pred = original_outputs, normalize=self.normalize_performance) #accuracy\n",
        "        else:\n",
        "          if self.exec_performance == self.exec_auc:\n",
        "            result_accuracy = self.auc_score(original_outputs, original_outputs) #AUC\n",
        "\n",
        "        result_pred = (original_outputs == data_exec_y.values) #binarization\n",
        "        df_loop_of_models.loc[len(df_loop_of_models)] = result_pred.astype(int)[:].tolist().insert(0,str_tmp) #boolean to int\n",
        "        df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_tmp, result_accuracy] \n",
        "      \n",
        "      #inset variation of ONE attribute in loop of models\n",
        "      if self.number_of_features_variation >= 1:\n",
        "        for _, variation in enumerate(self.exec_variation_method):\n",
        "          for id,c in enumerate(data_exec_x.columns):\n",
        "            #criando cópia do dado inicial\n",
        "            data_exec_x_copy = data_exec_x.copy()\n",
        "            if variation == self.exec_permutation:\n",
        "              #trocando posições de cada instância do atributo da vez\n",
        "              random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "              data_exec_x_copy[c] = data_exec_x_copy[c].values[random_id]\n",
        "              method = 'Permutation'\n",
        "            else:\n",
        "              if variation == self.exec_noise:\n",
        "                #aplica ruido a cada instâcia do atributo da vez\n",
        "                noise = np.random.normal(0, 1, number_of_instances)\n",
        "                data_exec_x_copy[c] = data_exec_x_copy[c] + noise\n",
        "                method = 'Noise'\n",
        "              else: \n",
        "                if variation == self.exec_zeros:\n",
        "                  #aplica zeros a cada instância do atributo da vez\n",
        "                  zeros = np.zeros(number_of_instances)\n",
        "                  data_exec_x_copy[c] = zeros\n",
        "                  method = 'Zeros'\n",
        "                else:\n",
        "                  if variation == self.exec_norm:\n",
        "                    #normaliza os elementos\n",
        "                    norm = np.linalg.norm(data_exec_x_copy[c])\n",
        "                    normal_array = data_exec_x_copy[c]/norm\n",
        "                    data_exec_x_copy[c] = normal_array\n",
        "                    method = 'Normalization'\n",
        "                  else:\n",
        "                    if variation == self.exec_ordup:\n",
        "                      #ordena em ordem crescente os elementos\n",
        "                      order_up = np.sort(data_exec_x_copy[c])\n",
        "                      data_exec_x_copy[c] = order_up\n",
        "                      method = 'Ordernation_Up'\n",
        "                    else:\n",
        "                      if variation == self.exec_orddown:\n",
        "                        #ordena em ordem decrescente os elementos\n",
        "                        order_down = -np.sort(-data_exec_x_copy[c])\n",
        "                        data_exec_x_copy[c] = order_down\n",
        "                        method = 'Ordernation_Down'\n",
        "                      else:\n",
        "                        if variation == self.exec_inver:\n",
        "                          #inverte os elementos\n",
        "                          transp = np.flipud(data_exec_x_copy[c])\n",
        "                          data_exec_x_copy[c] = transp\n",
        "                          method = 'Invertion'\n",
        "                        else:\n",
        "                          if variation == self.exec_binning:\n",
        "                            #inverte os elementos\n",
        "                            mean_arr = np.mean(data_exec_x_copy[c])\n",
        "                            binn = np.digitize(data_exec_x_copy[c],bins=[mean_arr])\n",
        "                            data_exec_x_copy[c] = binn\n",
        "                            method = 'Binning'\n",
        "                          else:\n",
        "                            if variation == self.exec_mult_neg:\n",
        "                              #multiplica por -1\n",
        "                              data_exec_x_copy[c] = data_exec_x_copy[c] * -1\n",
        "                              method = 'MultNeg'\n",
        "                            else:\n",
        "                              if variation == self.exec_mean:\n",
        "                                #mean\n",
        "                                inst =  len(data_exec_x_copy[c])\n",
        "                                data_exec_x_copy[c] = [statistics.mean(data_exec_x_copy[c])]*inst\n",
        "                                method = 'Mean'\n",
        "                              else:\n",
        "                                if variation == self.exec_std:\n",
        "                                  #std\n",
        "                                  inst =  len(data_exec_x_copy[c])\n",
        "                                  data_exec_x_copy[c] = [statistics.stdev(data_exec_x_copy[c])]*inst\n",
        "                                  method = 'Std'\n",
        "                                else:\n",
        "                                  if variation == self.exec_zscore:\n",
        "                                    #zscore\n",
        "                                    data_exec_x_copy[c] = self.z_score_serie(data_exec_x_copy[c])\n",
        "                                    method = 'Zscore'\n",
        "\n",
        "            if self.verbose:\n",
        "              print('')\n",
        "              print(method,' of ',c)\n",
        "              print(data_exec_x_copy)\n",
        "            if self.verbose_graph:\n",
        "              data_exec_x_copy.plot.kde(by=data_exec_x_copy.columns, alpha=0.5,title=str(method+' of '+c))\n",
        "\n",
        "            result_pred = model.predict(data_exec_x_copy) #prediction\n",
        "\n",
        "            if self.exec_performance == self.exec_accuracy:\n",
        "              result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=self.normalize_performance) #accuracy\n",
        "            else:\n",
        "              if self.exec_performance == self.exec_auc:\n",
        "                result_accuracy = self.auc_score(original_outputs, result_pred) #AUC\n",
        "\n",
        "            result_pred = (result_pred == original_outputs) #binarization\n",
        "            str_model_name = 'Clf '+method+' \"'+str(c)+'\"'\n",
        "            self.list_clf_loop.append(str_model_name)\n",
        "            df_loop_of_models.loc[len(df_loop_of_models)] = result_pred.astype(int)[:].tolist().insert(0,str_model_name) #boolean to int\n",
        "            df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n",
        "\n",
        "      #inset invertion of TWO attributes in loop of models\n",
        "      if self.number_of_features_variation >= 2:\n",
        "        for _,variation in enumerate(self.exec_variation_method):\n",
        "          for id1,c1 in enumerate(data_exec_x.columns):\n",
        "            for id2,c2 in enumerate(data_exec_x.columns):\n",
        "              if id2 > id1:\n",
        "                #criando cópia do dado inicial\n",
        "                data_exec_x_copy = data_exec_x.copy()\n",
        "                if variation == self.exec_permutation:\n",
        "                  #trocando posições de cada instância do atributo da vez\n",
        "                  random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                  data_exec_x_copy[c1] = data_exec_x_copy[c1].values[random_id]\n",
        "                  random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                  data_exec_x_copy[c2] = data_exec_x_copy[c2].values[random_id]\n",
        "                  method = 'Permutation'\n",
        "                else:\n",
        "                  if variation == self.exec_noise:\n",
        "                    #aplica ruido a cada instâcia do atributo da vez\n",
        "                    noise = np.random.normal(0, 1, number_of_instances)\n",
        "                    data_exec_x_copy[c1] = data_exec_x_copy[c1] + noise\n",
        "                    noise = np.random.normal(0, 1, number_of_instances)\n",
        "                    data_exec_x_copy[c2] = data_exec_x_copy[c2] + noise\n",
        "                    method = 'Noise'\n",
        "                  else:\n",
        "                    if variation == self.exec_zeros:\n",
        "                      #aplica zeros a cada instância do atributo da vez\n",
        "                      zeros = np.zeros(number_of_instances)\n",
        "                      data_exec_x_copy[c1] = zeros\n",
        "                      data_exec_x_copy[c2] = zeros\n",
        "                      method = 'Zeros'\n",
        "                    else:\n",
        "                      if variation == self.exec_norm:\n",
        "                        #normaliza os elementos\n",
        "                        norm = np.linalg.norm(data_exec_x_copy[c1])\n",
        "                        normal_array = data_exec_x_copy[c1]/norm\n",
        "                        data_exec_x_copy[c1] = normal_array\n",
        "                        norm = np.linalg.norm(data_exec_x_copy[c2])\n",
        "                        normal_array = data_exec_x_copy[c2]/norm\n",
        "                        data_exec_x_copy[c2] = normal_array\n",
        "                        method = 'Normalization'\n",
        "                      else:\n",
        "                        if variation == self.exec_ordup:\n",
        "                          #ordena em ordem crescente os elementos\n",
        "                          order_up = np.sort(data_exec_x_copy[c1])\n",
        "                          data_exec_x_copy[c1] = order_up\n",
        "                          order_up = np.sort(data_exec_x_copy[c2])\n",
        "                          data_exec_x_copy[c2] = order_up\n",
        "                          method = 'Ordernation_Up'\n",
        "                        else:\n",
        "                          if variation == self.exec_orddown:\n",
        "                            #ordena em ordem decrescente os elementos\n",
        "                            order_down = -np.sort(-data_exec_x_copy[c1])\n",
        "                            data_exec_x_copy[c1] = order_down\n",
        "                            order_down = -np.sort(-data_exec_x_copy[c2])\n",
        "                            data_exec_x_copy[c2] = order_down\n",
        "                            method = 'Ordernation_Down'\n",
        "                          else:\n",
        "                            if variation == self.exec_inver:\n",
        "                              #inverte os elementos\n",
        "                              transp = np.flipud(data_exec_x_copy[c1])\n",
        "                              data_exec_x_copy[c1] = transp\n",
        "                              transp = np.flipud(data_exec_x_copy[c2])\n",
        "                              data_exec_x_copy[c2] = transp\n",
        "                              method = 'Invertion'\n",
        "                            else:\n",
        "                              if variation == self.exec_binning:\n",
        "                                #inverte os elementos\n",
        "                                mean_arr = np.mean(data_exec_x_copy[c1])\n",
        "                                binn = np.digitize(data_exec_x_copy[c1],bins=[mean_arr])\n",
        "                                data_exec_x_copy[c1] = binn\n",
        "                                mean_arr = np.mean(data_exec_x_copy[c2])\n",
        "                                binn = np.digitize(data_exec_x_copy[c2],bins=[mean_arr])\n",
        "                                data_exec_x_copy[c2] = binn\n",
        "                                method = 'Binning'\n",
        "                              else:\n",
        "                                if variation == self.exec_mult_neg:\n",
        "                                  #multiplica por -1\n",
        "                                  data_exec_x_copy[c1] = data_exec_x_copy[c1] * -1\n",
        "                                  data_exec_x_copy[c2] = data_exec_x_copy[c2] * -1\n",
        "                                  method = 'MultNeg'\n",
        "                                else:\n",
        "                                  if variation == self.exec_mean:\n",
        "                                    #mean\n",
        "                                    inst =  len(data_exec_x_copy[c1])\n",
        "                                    data_exec_x_copy[c1] = [statistics.mean(data_exec_x_copy[c1])]*inst\n",
        "                                    data_exec_x_copy[c2] = [statistics.mean(data_exec_x_copy[c2])]*inst\n",
        "                                    method = 'Mean'\n",
        "                                  else:\n",
        "                                    if variation == self.exec_std:\n",
        "                                      #std\n",
        "                                      inst =  len(data_exec_x_copy[c1])\n",
        "                                      data_exec_x_copy[c1] = [statistics.stdev(data_exec_x_copy[c1])]*inst\n",
        "                                      data_exec_x_copy[c2] = [statistics.stdev(data_exec_x_copy[c2])]*inst\n",
        "                                      method = 'Std'\n",
        "                                    else:\n",
        "                                      if variation == self.exec_zscore:\n",
        "                                        #zscore\n",
        "                                        data_exec_x_copy[c1] = self.z_score_serie(data_exec_x_copy[c1])\n",
        "                                        data_exec_x_copy[c2] = self.z_score_serie(data_exec_x_copy[c2])\n",
        "                                        method = 'Zscore'\n",
        "\n",
        "                str_model_name = 'Clf '+method+' \"'+str(c1)+'\" and \"'+str(c2)+'\"'\n",
        "                if self.verbose:\n",
        "                  print('')\n",
        "                  print(str_model_name)\n",
        "                  print(data_exec_x_copy)\n",
        "                if self.verbose_graph:\n",
        "                  data_exec_x_copy.plot.kde(by=data_exec_x_copy.columns, alpha=0.5,title=str_model_name)\n",
        "\n",
        "                #executando o modelo com o atributo da vez embaralhado\n",
        "                result_pred = model.predict(data_exec_x_copy) #prediction\n",
        "\n",
        "                if self.exec_performance == self.exec_accuracy:\n",
        "                  result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=self.normalize_performance) #accuracy\n",
        "                else:\n",
        "                  if self.exec_performance == self.exec_auc:\n",
        "                    result_accuracy = self.auc_score(original_outputs, result_pred) #AUC\n",
        "\n",
        "                result_pred = (result_pred == original_outputs) #binarization\n",
        "                str_model_name = 'Clf '+method+' \"'+str(c1)+'\" and \"'+str(c2)+'\"'\n",
        "                self.list_clf_loop.append(str_model_name)\n",
        "                df_loop_of_models.loc[len(df_loop_of_models)] = result_pred.astype(int)[:].tolist().insert(0,str_model_name) #boolean to int\n",
        "                df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n",
        "              else:\n",
        "                pass\n",
        "\n",
        "      #inset invertion of Three attributes in loop of models\n",
        "      if self.number_of_features_variation >= 3:\n",
        "        for _, variation in enumerate(self.exec_variation_method):\n",
        "          for id1,c1 in enumerate(data_exec_x.columns):\n",
        "            for id2,c2 in enumerate(data_exec_x.columns):\n",
        "              for id3,c3 in enumerate(data_exec_x.columns):\n",
        "                if id3 > id2 and id2 > id1:\n",
        "                  #criando cópia do dado inicial\n",
        "                  data_exec_x_copy = data_exec_x.copy()\n",
        "                  if variation == self.exec_permutation:\n",
        "                    #trocando posições de cada instância do atributo da vez\n",
        "                    random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                    data_exec_x_copy[c1] = data_exec_x_copy[c1].values[random_id]\n",
        "                    random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                    data_exec_x_copy[c2] = data_exec_x_copy[c2].values[random_id]\n",
        "                    random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                    data_exec_x_copy[c3] = data_exec_x_copy[c3].values[random_id]\n",
        "                    method = 'Permutation'\n",
        "                  else:\n",
        "                    if variation == self.exec_noise:\n",
        "                      #aplica ruido a cada instâcia do atributo da vez\n",
        "                      noise = np.random.normal(0, 1, number_of_instances)\n",
        "                      data_exec_x_copy[c1] = data_exec_x_copy[c1] + noise\n",
        "                      noise = np.random.normal(0, 1, number_of_instances)\n",
        "                      data_exec_x_copy[c2] = data_exec_x_copy[c2] + noise\n",
        "                      noise = np.random.normal(0, 1, number_of_instances)\n",
        "                      data_exec_x_copy[c3] = data_exec_x_copy[c3] + noise\n",
        "                      method = 'Noise'\n",
        "                    else:\n",
        "                      if variation == self.exec_zeros:\n",
        "                        #aplica zeros a cada instância do atributo da vez\n",
        "                        zeros = np.zeros(number_of_instances)\n",
        "                        data_exec_x_copy[c1] = zeros\n",
        "                        data_exec_x_copy[c2] = zeros\n",
        "                        data_exec_x_copy[c3] = zeros\n",
        "                        method = 'Zeros'\n",
        "                      else:\n",
        "                        if variation == self.exec_norm:\n",
        "                          #normaliza os elementos\n",
        "                          norm = np.linalg.norm(data_exec_x_copy[c1])\n",
        "                          normal_array = data_exec_x_copy[c1]/norm\n",
        "                          data_exec_x_copy[c1] = normal_array\n",
        "                          norm = np.linalg.norm(data_exec_x_copy[c2])\n",
        "                          normal_array = data_exec_x_copy[c2]/norm\n",
        "                          data_exec_x_copy[c2] = normal_array\n",
        "                          normal_array = data_exec_x_copy[c3]/norm\n",
        "                          data_exec_x_copy[c3] = normal_array\n",
        "                          method = 'Normalization'\n",
        "                        else:\n",
        "                          if variation == self.exec_ordup:\n",
        "                            #ordena em ordem crescente os elementos\n",
        "                            order_up = np.sort(data_exec_x_copy[c1])\n",
        "                            data_exec_x_copy[c1] = order_up\n",
        "                            order_up = np.sort(data_exec_x_copy[c2])\n",
        "                            data_exec_x_copy[c2] = order_up\n",
        "                            order_up = np.sort(data_exec_x_copy[c3])\n",
        "                            data_exec_x_copy[c3] = order_up\n",
        "                            method = 'Ordernation_Up'\n",
        "                          else:\n",
        "                            if variation == self.exec_orddown:\n",
        "                              #ordena em ordem decrescente os elementos\n",
        "                              order_down = -np.sort(-data_exec_x_copy[c1])\n",
        "                              data_exec_x_copy[c1] = order_down\n",
        "                              order_down = -np.sort(-data_exec_x_copy[c2])\n",
        "                              data_exec_x_copy[c2] = order_down\n",
        "                              order_down = -np.sort(-data_exec_x_copy[c3])\n",
        "                              data_exec_x_copy[c3] = order_down\n",
        "                              method = 'Ordernation_Down'\n",
        "                            else:\n",
        "                              if variation == self.exec_inver:\n",
        "                                #inverte os elementos\n",
        "                                transp = np.flipud(data_exec_x_copy[c1])\n",
        "                                data_exec_x_copy[c1] = transp\n",
        "                                transp = np.flipud(data_exec_x_copy[c2])\n",
        "                                data_exec_x_copy[c2] = transp\n",
        "                                transp = np.flipud(data_exec_x_copy[c3])\n",
        "                                data_exec_x_copy[c3] = transp\n",
        "                                method = 'Invertion'\n",
        "                              else:\n",
        "                                if variation == self.exec_binning:\n",
        "                                  #inverte os elementos\n",
        "                                  mean_arr = np.mean(data_exec_x_copy[c1])\n",
        "                                  binn = np.digitize(data_exec_x_copy[c1],bins=[mean_arr])\n",
        "                                  data_exec_x_copy[c1] = binn\n",
        "                                  mean_arr = np.mean(data_exec_x_copy[c2])\n",
        "                                  binn = np.digitize(data_exec_x_copy[c2],bins=[mean_arr])\n",
        "                                  data_exec_x_copy[c2] = binn\n",
        "                                  mean_arr = np.mean(data_exec_x_copy[c3])\n",
        "                                  binn = np.digitize(data_exec_x_copy[c3],bins=[mean_arr])\n",
        "                                  data_exec_x_copy[c3] = binn\n",
        "                                  method = 'Binning'\n",
        "                                else:\n",
        "                                  if variation == self.exec_mult_neg:\n",
        "                                    #multiplica por -1\n",
        "                                    data_exec_x_copy[c1] = data_exec_x_copy[c1] * -1\n",
        "                                    data_exec_x_copy[c2] = data_exec_x_copy[c2] * -1\n",
        "                                    data_exec_x_copy[c3] = data_exec_x_copy[c3] * -1\n",
        "                                    method = 'MultNeg'\n",
        "                                  else:\n",
        "                                    if variation == self.exec_mean:\n",
        "                                      #mean\n",
        "                                      inst =  len(data_exec_x_copy[c1])\n",
        "                                      data_exec_x_copy[c1] = [statistics.mean(data_exec_x_copy[c1])]*inst\n",
        "                                      data_exec_x_copy[c2] = [statistics.mean(data_exec_x_copy[c2])]*inst\n",
        "                                      data_exec_x_copy[c3] = [statistics.mean(data_exec_x_copy[c3])]*inst\n",
        "                                      method = 'Mean'\n",
        "                                    else:\n",
        "                                      if variation == self.exec_std:\n",
        "                                        #std\n",
        "                                        inst =  len(data_exec_x_copy[c1])\n",
        "                                        data_exec_x_copy[c1] = [statistics.stdev(data_exec_x_copy[c1])]*inst\n",
        "                                        data_exec_x_copy[c2] = [statistics.stdev(data_exec_x_copy[c2])]*inst\n",
        "                                        data_exec_x_copy[c3] = [statistics.stdev(data_exec_x_copy[c3])]*inst\n",
        "                                        method = 'Std'\n",
        "                                      else:\n",
        "                                        if variation == self.exec_zscore:\n",
        "                                          #zscore\n",
        "                                          data_exec_x_copy[c1] = self.z_score_serie(data_exec_x_copy[c1])\n",
        "                                          data_exec_x_copy[c2] = self.z_score_serie(data_exec_x_copy[c2])\n",
        "                                          data_exec_x_copy[c3] = self.z_score_serie(data_exec_x_copy[c3])\n",
        "                                          method = 'Zscore'\n",
        "\n",
        "                    \n",
        "                  str_model_name = 'Clf '+method+' \"'+str(c1)+'\" and \"'+str(c2)+'\" and \"'+str(c3)+'\"'\n",
        "                  if self.verbose:\n",
        "                    print('')\n",
        "                    print(str_model_name)\n",
        "                    print(data_exec_x_copy)\n",
        "                  if self.verbose_graph:\n",
        "                    data_exec_x_copy.plot.kde(by=data_exec_x_copy.columns, alpha=0.5,title=str_model_name)\n",
        "\n",
        "                  \n",
        "                  result_pred = model.predict(data_exec_x_copy) #prediction\n",
        "\n",
        "                  if self.exec_performance == self.exec_accuracy:\n",
        "                    result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=self.normalize_performance) #accuracy\n",
        "                  else:\n",
        "                    if self.exec_performance == self.exec_auc:\n",
        "                      result_accuracy = self.auc_score(original_outputs, result_pred) #AUC\n",
        "\n",
        "                  result_pred = (result_pred == original_outputs) #binarization\n",
        "                  self.list_clf_loop.append(str_model_name)\n",
        "                  df_loop_of_models.loc[len(df_loop_of_models)] = result_pred.astype(int)[:].tolist().insert(0,str_model_name) #boolean to int\n",
        "                  df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n",
        "                else:\n",
        "                  pass\n",
        "\n",
        "      #inset invertion of Four attributes in loop of models\n",
        "      if self.number_of_features_variation == 4:\n",
        "        for _, variation in enumerate(self.exec_variation_method):\n",
        "          for id1,c1 in enumerate(data_exec_x.columns):\n",
        "            for id2,c2 in enumerate(data_exec_x.columns):\n",
        "              for id3,c3 in enumerate(data_exec_x.columns):\n",
        "                for id4,c4 in enumerate(data_exec_x.columns):\n",
        "                  if id4 > id3 and id3 > id2 and id2 > id1:\n",
        "                    #criando cópia do dado inicial\n",
        "                    data_exec_x_copy = data_exec_x.copy()\n",
        "                    if variation == self.exec_permutation:\n",
        "                      #trocando posições de cada instância do atributo da vez\n",
        "                      random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                      data_exec_x_copy[c1] = data_exec_x_copy[c1].values[random_id]\n",
        "                      random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                      data_exec_x_copy[c2] = data_exec_x_copy[c2].values[random_id]\n",
        "                      random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                      data_exec_x_copy[c3] = data_exec_x_copy[c3].values[random_id]\n",
        "                      random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                      data_exec_x_copy[c4] = data_exec_x_copy[c4].values[random_id]\n",
        "                      method = 'Permutation'\n",
        "                    else:\n",
        "                      if variation == self.exec_noise:\n",
        "                        #aplica ruido a cada instâcia do atributo da vez\n",
        "                        noise = np.random.normal(0, 1, number_of_instances)\n",
        "                        data_exec_x_copy[c1] = data_exec_x_copy[c1] + noise\n",
        "                        noise = np.random.normal(0, 1, number_of_instances)\n",
        "                        data_exec_x_copy[c2] = data_exec_x_copy[c2] + noise\n",
        "                        noise = np.random.normal(0, 1, number_of_instances)\n",
        "                        data_exec_x_copy[c3] = data_exec_x_copy[c3] + noise\n",
        "                        noise = np.random.normal(0, 1, number_of_instances)\n",
        "                        data_exec_x_copy[c4] = data_exec_x_copy[c4] + noise\n",
        "                        method = 'Noise'\n",
        "                      else:\n",
        "                        if variation == self.exec_zeros:\n",
        "                          #aplica zeros a cada instância do atributo da vez\n",
        "                          zeros = np.zeros(number_of_instances)\n",
        "                          data_exec_x_copy[c1] = zeros\n",
        "                          data_exec_x_copy[c2] = zeros\n",
        "                          data_exec_x_copy[c3] = zeros\n",
        "                          data_exec_x_copy[c4] = zeros\n",
        "                          method = 'Zeros'\n",
        "                        else:\n",
        "                          if variation == self.exec_norm:\n",
        "                            #normaliza os elementos\n",
        "                            norm = np.linalg.norm(data_exec_x_copy[c1])\n",
        "                            normal_array = data_exec_x_copy[c1]/norm\n",
        "                            data_exec_x_copy[c1] = normal_array\n",
        "                            norm = np.linalg.norm(data_exec_x_copy[c2])\n",
        "                            normal_array = data_exec_x_copy[c2]/norm\n",
        "                            data_exec_x_copy[c2] = normal_array\n",
        "                            normal_array = data_exec_x_copy[c3]/norm\n",
        "                            data_exec_x_copy[c3] = normal_array\n",
        "                            normal_array = data_exec_x_copy[c4]/norm\n",
        "                            data_exec_x_copy[c4] = normal_array\n",
        "                            method = 'Normalization'\n",
        "                          else:\n",
        "                            if variation == self.exec_ordup:\n",
        "                              #ordena em ordem crescente os elementos\n",
        "                              order_up = np.sort(data_exec_x_copy[c1])\n",
        "                              data_exec_x_copy[c1] = order_up\n",
        "                              order_up = np.sort(data_exec_x_copy[c2])\n",
        "                              data_exec_x_copy[c2] = order_up\n",
        "                              order_up = np.sort(data_exec_x_copy[c3])\n",
        "                              data_exec_x_copy[c3] = order_up\n",
        "                              order_up = np.sort(data_exec_x_copy[c4])\n",
        "                              data_exec_x_copy[c4] = order_up\n",
        "                              method = 'Ordernation_Up'\n",
        "                            else:\n",
        "                              if variation == self.exec_orddown:\n",
        "                                #ordena em ordem decrescente os elementos\n",
        "                                order_down = -np.sort(-data_exec_x_copy[c1])\n",
        "                                data_exec_x_copy[c1] = order_down\n",
        "                                order_down = -np.sort(-data_exec_x_copy[c2])\n",
        "                                data_exec_x_copy[c2] = order_down\n",
        "                                order_down = -np.sort(-data_exec_x_copy[c3])\n",
        "                                data_exec_x_copy[c3] = order_down\n",
        "                                order_down = -np.sort(-data_exec_x_copy[c4])\n",
        "                                data_exec_x_copy[c4] = order_down\n",
        "                                method = 'Ordernation_Down'\n",
        "                              else:\n",
        "                                if variation == self.exec_inver:\n",
        "                                  #inverte os elementos\n",
        "                                  transp = np.flipud(data_exec_x_copy[c1])\n",
        "                                  data_exec_x_copy[c1] = transp\n",
        "                                  transp = np.flipud(data_exec_x_copy[c2])\n",
        "                                  data_exec_x_copy[c2] = transp\n",
        "                                  transp = np.flipud(data_exec_x_copy[c3])\n",
        "                                  data_exec_x_copy[c3] = transp\n",
        "                                  transp = np.flipud(data_exec_x_copy[c4])\n",
        "                                  data_exec_x_copy[c4] = transp\n",
        "                                  method = 'Invertion'\n",
        "                                else:\n",
        "                                  if variation == self.exec_binning:\n",
        "                                    #inverte os elementos\n",
        "                                    mean_arr = np.mean(data_exec_x_copy[c1])\n",
        "                                    binn = np.digitize(data_exec_x_copy[c1],bins=[mean_arr])\n",
        "                                    data_exec_x_copy[c1] = binn\n",
        "                                    mean_arr = np.mean(data_exec_x_copy[c2])\n",
        "                                    binn = np.digitize(data_exec_x_copy[c2],bins=[mean_arr])\n",
        "                                    data_exec_x_copy[c2] = binn\n",
        "                                    mean_arr = np.mean(data_exec_x_copy[c3])\n",
        "                                    binn = np.digitize(data_exec_x_copy[c3],bins=[mean_arr])\n",
        "                                    data_exec_x_copy[c3] = binn\n",
        "                                    mean_arr = np.mean(data_exec_x_copy[c4])\n",
        "                                    binn = np.digitize(data_exec_x_copy[c4],bins=[mean_arr])\n",
        "                                    data_exec_x_copy[c4] = binn\n",
        "                                    method = 'Binning'\n",
        "                                  else:\n",
        "                                    if variation == self.exec_mult_neg:\n",
        "                                      #multiplica por -1\n",
        "                                      data_exec_x_copy[c1] = data_exec_x_copy[c1] * -1\n",
        "                                      data_exec_x_copy[c2] = data_exec_x_copy[c2] * -1\n",
        "                                      data_exec_x_copy[c3] = data_exec_x_copy[c3] * -1\n",
        "                                      data_exec_x_copy[c4] = data_exec_x_copy[c4] * -1\n",
        "                                      method = 'MultNeg'\n",
        "                                    else:\n",
        "                                      if variation == self.exec_mean:\n",
        "                                        #mean\n",
        "                                        inst =  len(data_exec_x_copy[c1])\n",
        "                                        data_exec_x_copy[c1] = [statistics.mean(data_exec_x_copy[c1])]*inst\n",
        "                                        data_exec_x_copy[c2] = [statistics.mean(data_exec_x_copy[c2])]*inst\n",
        "                                        data_exec_x_copy[c3] = [statistics.mean(data_exec_x_copy[c3])]*inst\n",
        "                                        data_exec_x_copy[c4] = [statistics.mean(data_exec_x_copy[c4])]*inst\n",
        "                                        method = 'Mean'\n",
        "                                      else:\n",
        "                                        if variation == self.exec_std:\n",
        "                                          #std\n",
        "                                          inst =  len(data_exec_x_copy[c1])\n",
        "                                          data_exec_x_copy[c1] = [statistics.stdev(data_exec_x_copy[c1])]*inst\n",
        "                                          data_exec_x_copy[c2] = [statistics.stdev(data_exec_x_copy[c2])]*inst\n",
        "                                          data_exec_x_copy[c3] = [statistics.stdev(data_exec_x_copy[c3])]*inst\n",
        "                                          data_exec_x_copy[c4] = [statistics.stdev(data_exec_x_copy[c4])]*inst\n",
        "                                          method = 'Std'\n",
        "                                        else:\n",
        "                                          if variation == self.exec_zscore:\n",
        "                                            #zscore\n",
        "                                            data_exec_x_copy[c1] = self.z_score_serie(data_exec_x_copy[c1])\n",
        "                                            data_exec_x_copy[c2] = self.z_score_serie(data_exec_x_copy[c2])\n",
        "                                            data_exec_x_copy[c3] = self.z_score_serie(data_exec_x_copy[c3])\n",
        "                                            data_exec_x_copy[c4] = self.z_score_serie(data_exec_x_copy[c4])\n",
        "                                            method = 'Zscore'\n",
        "                    \n",
        "                    str_model_name = 'Clf '+method+' \"'+str(c1)+'\" and \"'+str(c2)+'\" and \"'+str(c3)+'\" and \"'+str(c4)+'\"'\n",
        "                    if self.verbose:\n",
        "                      print('')\n",
        "                      print(str_model_name)\n",
        "                      print(data_exec_x_copy)\n",
        "                    if self.verbose_graph:\n",
        "                      data_exec_x_copy.plot.kde(by=data_exec_x_copy.columns, alpha=0.5,title=str_model_name)\n",
        "\n",
        "                    result_pred = model.predict(data_exec_x_copy) #prediction\n",
        "\n",
        "                    if self.exec_performance == self.exec_accuracy:\n",
        "                      result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=self.normalize_performance) #accuracy\n",
        "                    else:\n",
        "                      if self.exec_performance == self.exec_auc:\n",
        "                        result_accuracy = self.auc_score(original_outputs, result_pred) #AUC\n",
        "\n",
        "                    result_pred = (result_pred == original_outputs) #binarization\n",
        "                    self.list_clf_loop.append(str_model_name)\n",
        "                    df_loop_of_models.loc[len(df_loop_of_models)] = result_pred.astype(int)[:].tolist().insert(0,str_model_name) #boolean to int\n",
        "                    df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n",
        "                  else:\n",
        "                    pass\n",
        "    else:\n",
        "      if self.exec_proposal == self.proposal_1_pool:\n",
        "        \n",
        "        model_copy = copy.deepcopy(model)\n",
        "        \n",
        "\n",
        "        if self.include_original_clf_data_pool:\n",
        "          original_outputs = model_copy.predict(X_test)\n",
        "          \n",
        "          if self.exec_performance == self.exec_accuracy:\n",
        "            result_accuracy = accuracy_score(y_true = original_outputs, y_pred = original_outputs, normalize=self.normalize_performance) #accuracy\n",
        "          else:\n",
        "            if self.exec_performance == self.exec_auc:\n",
        "              result_accuracy = self.auc_score(original_outputs, original_outputs) #AUC\n",
        "          \n",
        "          result_pred = (original_outputs == original_outputs) #binarization\n",
        "          \n",
        "\n",
        "          str_model_name = 'Original model'\n",
        "          self.list_clf_pool.append(str_model_name)\n",
        "          df_loop_of_models.loc[len(df_loop_of_models)] = result_pred.astype(int)[:].tolist().insert(0,str_model_name) #boolean to int\n",
        "          df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n",
        "          if self.verbose:\n",
        "            print('')\n",
        "            print(str_model_name)\n",
        "            print(X_test)\n",
        "        \n",
        "        ps = self.powerSetLimited(data_exec_x.columns, self.number_of_features_deletion) #powerset of all features\n",
        "        \n",
        "        for _, ps_c in enumerate(ps):\n",
        "          data_train_x_copy = X_train.copy()\n",
        "          data_test_x_copy = X_test.copy()\n",
        "          for _, c in enumerate(ps_c):\n",
        "            flag_none = True\n",
        "            #remove feature c\n",
        "            data_train_x_copy = data_train_x_copy.drop(c, axis='columns')\n",
        "            data_test_x_copy = data_test_x_copy.drop(c, axis='columns')\n",
        "\n",
        "          if len(data_train_x_copy.columns) == 0:\n",
        "            break\n",
        "\n",
        "          #train new model\n",
        "          model_copy.fit(data_train_x_copy, y_train)\n",
        "\n",
        "          result_pred = model_copy.predict(data_test_x_copy)\n",
        "          if self.exec_performance == self.exec_accuracy:\n",
        "            result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=self.normalize_performance) #accuracy\n",
        "          else:\n",
        "            if self.exec_performance == self.exec_auc:\n",
        "              result_accuracy = self.auc_score(original_outputs, result_pred) #AUC\n",
        "\n",
        "          result_pred = (result_pred == original_outputs) #binarization\n",
        "            \n",
        "          str_model_name = 'Clf feature elimination: '\n",
        "          for _, i in enumerate(ps_c):\n",
        "            str_model_name = str_model_name + '\"'+str(i)+'\" '\n",
        "          self.list_clf_pool.append(str_model_name)\n",
        "          df_loop_of_models.loc[len(df_loop_of_models)] = result_pred.astype(int)[:].tolist().insert(0,str_model_name) #boolean to int\n",
        "          df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n",
        "          if self.verbose:\n",
        "            print('')\n",
        "            print(str_model_name)\n",
        "            print(data_test_x_copy)\n",
        "\n",
        "    df_loop_of_models.set_index('Clf')\n",
        "    if self.verbose:\n",
        "      print('Resume Loop of model')\n",
        "      print(df_loop_of_models)\n",
        "      print()\n",
        "      print('Resume Loop of model accuracy')\n",
        "      print(df_loop_of_models_performance)\n",
        "\n",
        "    df = df_loop_of_models\n",
        "    df.to_csv(self.path_content+self.path_irt+\"/tabela_base_para_executar_irt.csv\")\n",
        "    if self.download_files:\n",
        "      files.download(self.path_content+self.path_irt+\"/tabela_base_para_executar_irt.csv\") \n",
        "\n",
        "    df = df_loop_of_models_performance\n",
        "    df.to_csv(self.path_content+self.path_irt+\"/tabela_base_para_executar_irt_accuracy.csv\",index=False)\n",
        "    if self.download_files:\n",
        "      files.download(self.path_content+self.path_irt+\"/tabela_base_para_executar_irt_accuracy.csv\")\n",
        "\n",
        "    return  df_loop_of_models, df_loop_of_models_performance\n",
        "\n",
        "  def run_irt(self, datasetName):\n",
        "\n",
        "\n",
        "    %rm -rf $self.path_content$self.path_irt'/irt_item_param.csv'\n",
        "    %rm -rf $self.path_content$self.path_irt'/irt_item_param_new.csv'\n",
        "    %rm -rf $self.path_content$self.path_irt'/OutExecution/theta_list.csv'\n",
        "    %rm -rf $self.path_content$self.path_irt'/OutExecution/score_total.csv'\n",
        "\n",
        "    !python decodIRT_MLtIRT.py -dir $self.path_irt -respMatrix $self.path_content$self.path_irt'/tabela_base_para_executar_irt.csv'\n",
        "\n",
        "    url = self.path_content+self.path_irt+'/irt_item_param.csv'\n",
        "    result_irt = pd.read_csv(url)\n",
        "    if self.download_files:\n",
        "      files.download(url) \n",
        "    \n",
        "    result_irt_new = result_irt.copy()\n",
        "\n",
        "    #save parameters of item by datset\n",
        "    result_irt_dataset = result_irt.copy()\n",
        "    result_irt_dataset.to_csv(self.path_content+self.path_irt+self.path_dataset+'/irt_item_param_'+datasetName+'.csv',index=False)\n",
        "    if self.download_files:\n",
        "      files.download(self.path_content+self.path_irt+self.path_dataset+'/irt_item_param_'+datasetName+'.csv')\n",
        "\n",
        "    if self.irt_divine == False:\n",
        "      result_irt_new['Adivinhacao'] = [0]*len(result_irt_new['Adivinhacao']) #anula os valores de adivinhação\n",
        "    if self.irt_difficulty == False:\n",
        "      result_irt_new['Dificuldade'] = [0]*len(result_irt_new['Dificuldade']) #anula os valores de dificuldade\n",
        "    if self.irt_discriminate == False:\n",
        "      result_irt_new['Discriminacao'] = [0]*len(result_irt_new['Discriminacao']) #anula os valores de Discriminacao\n",
        "\n",
        "    result_irt_new.to_csv(self.path_content+self.path_irt+'/irt_item_param_new.csv',index=False)\n",
        "\n",
        "    !python decodIRT_analysis.py -dir $self.path_irt -nameData OutExecution -respMatrix $self.path_content$self.path_irt'/tabela_base_para_executar_irt.csv' -IRTparam $self.path_content$self.path_irt'/irt_item_param_new.csv' -accur $self.path_content$self.path_irt'/tabela_base_para_executar_irt_accuracy.csv' -scoreAll -save $self.irt_method -missing\n",
        "\n",
        "    \n",
        "    %cat IRT_param_freq.txt\n",
        "    %cp IRT_param_freq.txt $self.path_content$self.path_irt$self.path_dataset'/IRT_param_freq_'$datasetName'.txt'\n",
        "    return result_irt_new, result_irt\n",
        "    \n",
        "  def run_calc(self, name_of_features_x,datasetName):\n",
        "\n",
        "    if self.exec_base_irt_score == self.exec_theta:\n",
        "      url = self.path_content+self.path_irt+'/OutExecution/theta_list.csv'\n",
        "      name_col = 'Theta'\n",
        "    else:\n",
        "      if self.exec_base_irt_score == self.exec_trueScore:\n",
        "        url = self.path_content+self.path_irt+'/OutExecution/score_total.csv'\n",
        "        name_col = 'Score'\n",
        "    \n",
        "    rank_theta = pd.read_csv(url)\n",
        "\n",
        "\n",
        "    if self.download_files:\n",
        "      files.download(url)\n",
        "    rank_theta = rank_theta.sort_values(name_col,ascending=True)\n",
        "    \n",
        "    # if exec_proposal == proposal_1_pool:\n",
        "    #   k = number_of_features*number_of_features_deletion*4\n",
        "    # else:\n",
        "    #   if exec_proposal == proposal_2_loop:\n",
        "    #     k = number_of_features*len(exec_variation_method)*number_of_features_variation\n",
        "    \n",
        "    \n",
        "    #rank_theta.plot.barh(x='Clf',y=name_col,figsize = (15,k),color='green')\n",
        "    rank_theta = rank_theta.set_index(keys='Clf')\n",
        "\n",
        "    if self.exec_proposal == self.proposal_2_loop:\n",
        "      rank_theta_loop = rank_theta.sort_values(by=name_col, ascending=True)\n",
        "\n",
        "      df_rank_final = pd.DataFrame(index=name_of_features_x, columns=[str('Final '+name_col)])\n",
        "      \n",
        "      for _, feature in enumerate(name_of_features_x):\n",
        "        if self.exec_calc_theta == self.theta_sum:\n",
        "          df_rank_final.loc[feature,str('Final '+name_col)] = sum(rank_theta_loop.filter(like='\"'+feature+'\"', axis='index')[name_col])\n",
        "        else:\n",
        "          if self.exec_calc_theta == self.theta_min:\n",
        "            df_rank_final.loc[feature,str('Final '+name_col)] = min(rank_theta_loop.filter(like='\"'+feature+'\"', axis='index')[name_col])\n",
        "          else:\n",
        "            if self.exec_calc_theta == self.theta_mean:\n",
        "              df_rank_final.loc[feature,str('Final '+name_col)] = statistics.mean(rank_theta_loop.filter(like='\"'+feature+'\"', axis='index')[name_col])\n",
        "\n",
        "      df_rank_final = df_rank_final.sort_values(by=str('Final '+name_col), ascending=True)\n",
        "      df_rank_final\n",
        "    else:\n",
        "      if self.exec_proposal == self.proposal_1_pool:\n",
        "\n",
        "        rank_theta_pool = rank_theta.sort_values(by=name_col, ascending=True)\n",
        "\n",
        "        df_rank_final = pd.DataFrame(index=name_of_features_x, columns=[str('Final '+name_col)])\n",
        "        \n",
        "        for _, feature in enumerate(name_of_features_x):\n",
        "          if self.exec_calc_theta == self.theta_sum:\n",
        "            df_rank_final.loc[feature,str('Final '+name_col)] = sum(rank_theta_pool.filter(like=feature, axis='index')[name_col])\n",
        "          else:\n",
        "            if self.exec_calc_theta == self.theta_min:\n",
        "              df_rank_final.loc[feature,str('Final '+name_col)] = min(rank_theta_pool.filter(like=feature, axis='index')[name_col])\n",
        "            else:\n",
        "              if self.exec_calc_theta == self.theta_mean:\n",
        "                df_rank_final.loc[feature,str('Final '+name_col)] = statistics.mean(rank_theta_pool.filter(like=feature, axis='index')[name_col])\n",
        "\n",
        "        df_rank_final = df_rank_final.sort_values(by=str('Final '+name_col), ascending=True)\n",
        "\n",
        "\n",
        "    \n",
        "    df_rank_final.to_csv(self.path_content+self.path_irt+self.path_dataset+'/rank_final_'+datasetName+'.csv',index=True)\n",
        "    return df_rank_final\n",
        "\n",
        "  def explainRankByEXirt(self, model, X_train, X_test, y_train, y_test,datasetName):\n",
        "\n",
        "    self.path_dataset = '/'+datasetName\n",
        "    self.dirByDataset(self.path_dataset)\n",
        "\n",
        "    if(self.exec_in == self.exec_test):\n",
        "      data_exec_x = X_test\n",
        "      data_exec_y = y_test \n",
        "    else:\n",
        "      data_exec_x = X_train\n",
        "      data_exec_y = y_train\n",
        "\n",
        "    \n",
        "    N = 500\n",
        "    if len(data_exec_y) > N:\n",
        "      data_sample = data_exec_x\n",
        "      data_sample['class'] = data_exec_y\n",
        "\n",
        "      #stratifier sampler\n",
        "      data_sample = data_sample.groupby('class', group_keys=False).apply(lambda x: x.sample(int(np.rint(N*len(x)/len(data_sample))))).sample(frac=1).reset_index(drop=True)\n",
        "      \n",
        "      data_exec_y = data_sample['class']\n",
        "      data_sample = data_sample.drop(labels='class', axis=1)\n",
        "      data_exec_x = data_sample\n",
        "\n",
        "    a, b = self.run_prepare(model, data_exec_x, data_exec_y, X_train, X_test, y_train, y_test)\n",
        "    \n",
        "    rirt_new, rirt = self.run_irt(datasetName)\n",
        "    \n",
        "    rank = self.run_calc(X_train.columns, datasetName)\n",
        "    \n",
        "    return list(rank.index), rank"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data and Pre-process"
      ],
      "metadata": {
        "id": "nvKrH0aUlvC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(df):\n",
        "    # copy the dataframe\n",
        "    df_norm = df.copy()\n",
        "    # apply min-max scaling\n",
        "    for column in df_norm.columns:\n",
        "        if(len(df_norm[column].unique()) > 1): #fix NaN generation\n",
        "          df_norm[column] = (df_norm[column] - df_norm[column].min()) / (df_norm[column].max() - df_norm[column].min())\n",
        "        else:\n",
        "          df_norm[column] = 0\n",
        "    return df_norm"
      ],
      "metadata": {
        "id": "2YGB9snVsqaZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select dataset name by openml link https://www.openml.org/search?sort=date\n",
        "dataset_name = \"pc1\""
      ],
      "metadata": {
        "id": "hSjFdmrjp9ui"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset by OpenML\n",
        "\n",
        "dataset = openml.datasets.get_dataset(dataset_name)\n",
        "X, Y, categorical_indicator, attribute_names = dataset.get_data(\n",
        "                  dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
        "\n",
        "#Preprocess Y and X numerics\n",
        "\n",
        "if (Y.dtype != 'numeric'):\n",
        "  Y = Y.astype(int)\n",
        "\n",
        "for i,c in enumerate(X.columns):\n",
        "  if (X[c].dtype != 'float64'):\n",
        "    X = X.astype(float)\n",
        "\n",
        "#Normalization\n",
        "X = normalize(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify=Y) # 70% training and 30% test\n",
        "\n"
      ],
      "metadata": {
        "id": "oYts5cLPlzTE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creation and prediction model"
      ],
      "metadata": {
        "id": "mtvHAgCLtPXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(200)\n",
        "model.fit(X_train, y_train)\n",
        "prediction = model.predict(X_test)"
      ],
      "metadata": {
        "id": "MgvqLmsum_nC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global explanation rank"
      ],
      "metadata": {
        "id": "_NNGxuw4ucIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = EXirt()"
      ],
      "metadata": {
        "id": "rhjOukpxtgXE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_explanation_attributes, global_explanation_attributes_scores = explainer.explainRankByEXirt(model, X_train, X_test, y_train, y_test,dataset_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "T8OEPD8bue2F",
        "outputId": "4b3f0525-65ad-4f63-9458-76052c9cc483"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/out_irt/tabela_base_para_executar_irt.csv': No such file or directory\n",
            "rm: cannot remove '/content/out_irt/tabela_base_para_executar_irt_accuracy.csv': No such file or directory\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_23757890-b883-4966-86a3-a9b29a53fbc8\", \"tabela_base_para_executar_irt.csv\", 157944)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c4205281-b395-4efd-9282-d3eb43ef500a\", \"tabela_base_para_executar_irt_accuracy.csv\", 23865)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando os parametros do IRT para o dataset:  /content/out_irt/tabela_base_para_executar_irt.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7139256c-94bf-4544-bc63-6380483c0870\", \"irt_item_param.csv\", 6237)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_89b4938a-1c19-4842-92b4-2cd5ef442aef\", \"irt_item_param_pc1.csv\", 6247)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As frequencias dos parametros de item foram salvas \\o/\n",
            "\n",
            "Todos os valores de Theta foram salvos \\o/\n",
            "No handles with labels found to put in legend.\n",
            "\n",
            "Os scores dos classificadores para todos os datasets foram salvos \\o/\n",
            "\n",
            "Porcentagem de itens com valores altos do parametro Discriminacao\n",
            "Dataset \t\t\t\t Percentual de itens\n",
            "OutExecution                                   100%\n",
            "------------------------------------------------------------\n",
            "Porcentagem de itens com valores altos do parametro Dificuldade\n",
            "Dataset \t\t\t\t Percentual de itens\n",
            "OutExecution                                     0%\n",
            "------------------------------------------------------------\n",
            "Porcentagem de itens com valores altos do parametro Advinhacao\n",
            "Dataset \t\t\t\t Percentual de itens\n",
            "OutExecution                                     0%\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1aed6968-8518-40a0-ba30-08614f2b20ab\", \"score_total.csv\", 26423)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_explanation_attributes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd-KdbaMo4Zy",
        "outputId": "9cb95eaf-cc54-40e9-f2ac-a52ab1ea9aa9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['locCodeAndComment',\n",
              " 'I',\n",
              " 'uniq_Opnd',\n",
              " 'lOBlank',\n",
              " 'total_Op',\n",
              " 'lOCode',\n",
              " 'loc',\n",
              " 'V',\n",
              " 'B',\n",
              " 'total_Opnd',\n",
              " 'T',\n",
              " 'E',\n",
              " 'L',\n",
              " 'v(g)',\n",
              " 'lOComment',\n",
              " 'D',\n",
              " 'uniq_Op',\n",
              " 'N',\n",
              " 'ev(g)',\n",
              " 'iv(G)',\n",
              " 'branchCount']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_explanation_attributes_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "84ZM0d12zP4q",
        "outputId": "be25a284-6c49-4425-9ca6-a0c7eebb26d6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Final Score\n",
              "locCodeAndComment  -114.02495\n",
              "I                 -113.956411\n",
              "uniq_Opnd         -113.812359\n",
              "lOBlank           -113.771792\n",
              "total_Op          -113.764184\n",
              "lOCode            -113.749034\n",
              "loc               -113.708599\n",
              "V                 -113.688393\n",
              "B                 -113.678247\n",
              "total_Opnd        -113.663088\n",
              "T                 -113.658017\n",
              "E                 -113.645385\n",
              "L                  -113.64033\n",
              "v(g)              -113.640324\n",
              "lOComment         -113.622673\n",
              "D                  -113.62011\n",
              "uniq_Op           -113.615074\n",
              "N                 -113.612527\n",
              "ev(g)             -113.594847\n",
              "iv(G)             -113.589797\n",
              "branchCount        -113.58726"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d12773e0-c419-437a-8583-b438f73427ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Final Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>locCodeAndComment</th>\n",
              "      <td>-114.02495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I</th>\n",
              "      <td>-113.956411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>uniq_Opnd</th>\n",
              "      <td>-113.812359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lOBlank</th>\n",
              "      <td>-113.771792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total_Op</th>\n",
              "      <td>-113.764184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lOCode</th>\n",
              "      <td>-113.749034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loc</th>\n",
              "      <td>-113.708599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V</th>\n",
              "      <td>-113.688393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>-113.678247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total_Opnd</th>\n",
              "      <td>-113.663088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T</th>\n",
              "      <td>-113.658017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E</th>\n",
              "      <td>-113.645385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>L</th>\n",
              "      <td>-113.64033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>v(g)</th>\n",
              "      <td>-113.640324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lOComment</th>\n",
              "      <td>-113.622673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D</th>\n",
              "      <td>-113.62011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>uniq_Op</th>\n",
              "      <td>-113.615074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>N</th>\n",
              "      <td>-113.612527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ev(g)</th>\n",
              "      <td>-113.594847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>iv(G)</th>\n",
              "      <td>-113.589797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>branchCount</th>\n",
              "      <td>-113.58726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d12773e0-c419-437a-8583-b438f73427ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d12773e0-c419-437a-8583-b438f73427ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d12773e0-c419-437a-8583-b438f73427ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fYRB58lNnHAX",
        "xQcwXWF97TrR",
        "nvKrH0aUlvC-",
        "mtvHAgCLtPXm",
        "_NNGxuw4ucIB"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}