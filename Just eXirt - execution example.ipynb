{"cells":[{"cell_type":"markdown","metadata":{"id":"kjIG882ZoyVl"},"source":["Simple example of eXirt's use"]},{"cell_type":"markdown","source":["Run all bullets in the sequence below!"],"metadata":{"id":"7Pzk_smLpiUR"}},{"cell_type":"markdown","metadata":{"id":"tM_sX-w4IcIJ"},"source":["\n","\n","Generate files?\n"]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"QVmQbyO6nk-W","executionInfo":{"status":"ok","timestamp":1673101790173,"user_tz":180,"elapsed":473,"user":{"displayName":"José Ribeiro","userId":"10789669540889156464"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":998,"status":"ok","timestamp":1673101309258,"user":{"displayName":"José Ribeiro","userId":"10789669540889156464"},"user_tz":180},"id":"6aEB6j65Imb4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6ee749a5-4dc5-4db3-91b5-fa0abc76a7cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove '/content/out_fig': No such file or directory\n","rm: cannot remove '/content/out_csv': No such file or directory\n","rm: cannot remove '/content/out_model': No such file or directory\n","rm: cannot remove '/content/out_irt': No such file or directory\n"]}],"source":["do_download = True\n","\n","path_content = '/content'\n","path_fig = '/out_fig'\n","path_csv = '/out_csv'\n","path_model = '/out_model'\n","path_irt = '/out_irt' \n","path_dataset = '/*'\n","\n","!rm -r $path_content$path_fig\n","!rm -r $path_content$path_csv\n","!rm -r $path_content$path_model\n","!rm -r $path_content$path_irt\n","\n","\n","!mkdir $path_content$path_fig\n","!mkdir $path_content$path_csv\n","!mkdir $path_content$path_model\n","!mkdir $path_content$path_irt\n","\n","def dirByDataset(datasetName):\n","  !mkdir $path_content$path_fig$datasetName\n","  !mkdir $path_content$path_csv$datasetName\n","  !mkdir $path_content$path_model$datasetName\n","  !mkdir $path_content$path_irt$datasetName"]},{"cell_type":"markdown","metadata":{"id":"fYRB58lNnHAX"},"source":["## Install dependences"]},{"cell_type":"code","source":["!pip install openml\n","!pip install catsim\n","\n","import openml\n","import pandas as pd\n","import statistics\n","import numpy as np\n","import random\n","import copy\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn import metrics\n","from google.colab import files\n","\n","\n","!wget https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_OtML.py\n","!wget https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_MLtIRT.py\n","!wget https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_analysis.py\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySk3bH_Vm1Cn","executionInfo":{"status":"ok","timestamp":1673101334960,"user_tz":180,"elapsed":24273,"user":{"displayName":"José Ribeiro","userId":"10789669540889156464"}},"outputId":"728b73fb-8b00-4702-dbe0-bacf4b30fa67"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openml\n","  Downloading openml-0.13.0-py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from openml) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from openml) (2.25.1)\n","Collecting minio\n","  Downloading minio-7.1.13-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting liac-arff>=2.4.0\n","  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from openml) (1.0.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from openml) (2.8.2)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.8/dist-packages (from openml) (9.0.0)\n","Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.8/dist-packages (from openml) (1.7.3)\n","Collecting xmltodict\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from openml) (1.3.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.0->openml) (2022.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil->openml) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->openml) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->openml) (1.2.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from minio->openml) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from minio->openml) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->openml) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->openml) (2.10)\n","Building wheels for collected packages: liac-arff\n","  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11732 sha256=f412cf20863ba35c30718e5ca2ae48fdd4cab0771f425459a5d7827a8a9b4e89\n","  Stored in directory: /root/.cache/pip/wheels/a2/de/68/bf3972de3ecb31e32bef59a7f4c75f0687a3674c476b347c14\n","Successfully built liac-arff\n","Installing collected packages: xmltodict, minio, liac-arff, openml\n","Successfully installed liac-arff-2.5.0 minio-7.1.13 openml-0.13.0 xmltodict-0.13.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting catsim\n","  Downloading catsim-0.17.2-py3-none-any.whl (32 kB)\n","Collecting json-tricks\n","  Downloading json_tricks-3.16.1-py2.py3-none-any.whl (27 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from catsim) (4.64.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from catsim) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from catsim) (1.21.6)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.8/dist-packages (from catsim) (2.8.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from catsim) (1.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from catsim) (1.7.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catsim) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catsim) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catsim) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catsim) (0.11.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->catsim) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->catsim) (1.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->catsim) (1.15.0)\n","Installing collected packages: json-tricks, catsim\n","Successfully installed catsim-0.17.2 json-tricks-3.16.1\n","--2023-01-07 14:22:15--  https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_OtML.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19052 (19K) [text/plain]\n","Saving to: ‘decodIRT_OtML.py’\n","\n","decodIRT_OtML.py    100%[===================>]  18.61K  --.-KB/s    in 0.001s  \n","\n","2023-01-07 14:22:16 (12.8 MB/s) - ‘decodIRT_OtML.py’ saved [19052/19052]\n","\n","--2023-01-07 14:22:16--  https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_MLtIRT.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 7453 (7.3K) [text/plain]\n","Saving to: ‘decodIRT_MLtIRT.py’\n","\n","decodIRT_MLtIRT.py  100%[===================>]   7.28K  --.-KB/s    in 0s      \n","\n","2023-01-07 14:22:16 (63.6 MB/s) - ‘decodIRT_MLtIRT.py’ saved [7453/7453]\n","\n","--2023-01-07 14:22:16--  https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_analysis.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 33818 (33K) [text/plain]\n","Saving to: ‘decodIRT_analysis.py’\n","\n","decodIRT_analysis.p 100%[===================>]  33.03K  --.-KB/s    in 0.004s  \n","\n","2023-01-07 14:22:17 (8.61 MB/s) - ‘decodIRT_analysis.py’ saved [33818/33818]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"xQcwXWF97TrR"},"source":["## eXirt tool"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"0Pvq-euegHVF","executionInfo":{"status":"ok","timestamp":1673101352751,"user_tz":180,"elapsed":4088,"user":{"displayName":"José Ribeiro","userId":"10789669540889156464"}}},"outputs":[],"source":["############## GENERAL CONTROL #######################\n","proposal_1_pool = 1\n","proposal_2_loop = 2\n","exec_proposal = proposal_2_loop\n","\n","# verbose\n","verbose = False\n","verbose_graph = False\n","\n","download_files = True\n","\n","# performance\n","exec_accuracy = 1\n","exec_auc = 2\n","exec_performance = exec_accuracy\n","normalize_performance = True\n","\n","####### IRT ################\n","#execute theta ou trueScore\n","exec_theta = 0\n","exec_trueScore = 1\n","exec_base_irt_score = exec_trueScore\n","\n","# calculo de  theta\n","theta_sum = 0\n","theta_min = 1\n","theta_mean = 2\n","exec_calc_theta = theta_mean\n","\n","\n","# irt algorithm ‘ternary’, ‘dichotomous’, ‘fibonacci’, ‘golden’, ‘brent’, ‘bounded’ and ‘golden2’\n","irt_method_fibonacci = '-metodo fibonacci'\n","irt_method_bounded = '-metodo bounded'\n","irt_method_ternary = '-metodo ternary' #long time execution\n","irt_method_dichotomous = '-metodo dichotomous' #long time execution\n","irt_method_golden = '-metodo golden'\n","irt_method_brent = '-metodo brent'\n","irt_method_golden2 = '-metodo golden2' #problem in execution\n","irt_method = irt_method_bounded\n","\n","# controle de propriedades do IRT\n","irt_discriminate = True #False remove the property by IRTs calc.\n","irt_difficulty = True #False remove the property by IRTs calc.\n","irt_divine = True #False remove the property by IRTs calc.\n","\n","############## PROPOSAL 1 POOL #######################\n","include_original_clf_data_pool = True\n","number_of_features_deletion = 2 # values 1 to ++\n","\n","list_clf_pool = [] #empity\n","\n","############## PROPOSAL 2 LOOP #######################\n","\n","include_original_clf_data_loop = True\n","number_of_features_variation = 2 # values 1 to 4\n","\n","# test or train\n","exec_test = 0\n","exec_train = 1\n","exec_in = exec_test\n","\n","#loop of models variation\n","exec_permutation = 0 # random base\n","exec_noise = 1 # random base\n","exec_zeros = 2\n","exec_norm = 3 \n","exec_ordup = 4\n","exec_orddown = 5\n","exec_inver = 6\n","exec_binning = 7\n","exec_mult_neg = 8\n","exec_mean = 9\n","exec_std = 10\n","exec_zscore = 11\n","exec_variation_method = [exec_mult_neg, exec_binning]\n","\n","#list of thetas\n","list_clf_loop = [] #empity\n","\n","########## global declaration #############\n","\n","# model = None\n","# X_train = None\n","# X_test = None\n","# y_test = None\n","# y_train = None\n","\n","def z_score_serie(s):\n","  # copy the dataframe\n","  s_std = s.copy()\n","  s_std = (s_std - s_std.mean()) / s_std.std()\n","  return s_std\n","\n","def auc_score(y, y_pred):\n","    \n","    fpr, tpr, thresholds = metrics.roc_curve(y, y_pred, pos_label=2)\n","    \n","    return metrics.auc(fpr, tpr)\n","\n","def powerSetLimited(s,l):\n","\n","    def powerset(s):\n","      x = len(s)\n","      masks = [1 << i for i in range(x)]\n","      for i in range(1 << x):\n","          yield [ss for mask, ss in zip(masks, s) if i & mask]\n","    \n","    psl = []\n","    ps = list(powerset(s))\n","    for _,i in enumerate(ps):\n","      if len(i) <= l and len(i)>0:\n","        psl.append(i)\n","    return psl\n","\n","def run_prepare(model,data_exec_x, data_exec_y, X_train, X_test, y_train, y_test):\n","  global path_dataset\n","  \n","  %rm $path_content$path_irt'/tabela_base_para_executar_irt.csv'\n","  %rm $path_content$path_irt'/tabela_base_para_executar_irt_accuracy.csv'\n","\n","\n","  #prediction\n","  original_outputs = model.predict(data_exec_x)\n","\n","\n","  #XAI-IRT\n","  # train, test, model and outputs\n","\n","  #Loop of models\n","  df_loop_of_models = pd.DataFrame()\n","  df_loop_of_models_performance = pd.DataFrame(columns=['Metodo','Acuracia'])\n","\n","\n","\n","  if exec_proposal == proposal_2_loop:\n","    if verbose:\n","      print('Original data')\n","      print(data_exec_x)\n","\n","    number_of_instances = len(data_exec_x)\n","\n","    if include_original_clf_data_loop:\n","      str_tmp = 'Clf original data'\n","      if exec_performance == exec_accuracy:\n","        result_accuracy = accuracy_score(y_true = original_outputs, y_pred = original_outputs, normalize=normalize_performance) #accuracy\n","      else:\n","        if exec_performance == exec_auc:\n","          result_accuracy = auc_score(original_outputs, original_outputs) #AUC\n","\n","      result_pred = (original_outputs == data_exec_y.values) #binarization\n","      df_loop_of_models[str_tmp] = result_pred.astype(int)[:] #boolean to int\n","      #myfix#df_loop_of_models_performance = df_loop_of_models_performance.append({'Metodo':str_tmp,'Acuracia':result_accuracy},ignore_index=True)\n","      df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_tmp, result_accuracy] \n","    \n","    #inset variation of ONE attribute in loop of models\n","    if number_of_features_variation >= 1:\n","      for _, variation in enumerate(exec_variation_method):\n","        for id,c in enumerate(data_exec_x.columns):\n","          #criando cópia do dado inicial\n","          data_exec_x_copy = data_exec_x.copy()\n","          if variation == exec_permutation:\n","            #trocando posições de cada instância do atributo da vez\n","            random_id = random.sample(range(0,number_of_instances), number_of_instances)\n","            data_exec_x_copy[c] = data_exec_x_copy[c].values[random_id]\n","            method = 'Permutation'\n","          else:\n","            if variation == exec_noise:\n","              #aplica ruido a cada instâcia do atributo da vez\n","              noise = np.random.normal(0, 1, number_of_instances)\n","              data_exec_x_copy[c] = data_exec_x_copy[c] + noise\n","              method = 'Noise'\n","            else: \n","              if variation == exec_zeros:\n","                #aplica zeros a cada instância do atributo da vez\n","                zeros = np.zeros(number_of_instances)\n","                data_exec_x_copy[c] = zeros\n","                method = 'Zeros'\n","              else:\n","                if variation == exec_norm:\n","                  #normaliza os elementos\n","                  norm = np.linalg.norm(data_exec_x_copy[c])\n","                  normal_array = data_exec_x_copy[c]/norm\n","                  data_exec_x_copy[c] = normal_array\n","                  method = 'Normalization'\n","                else:\n","                  if variation == exec_ordup:\n","                    #ordena em ordem crescente os elementos\n","                    order_up = np.sort(data_exec_x_copy[c])\n","                    data_exec_x_copy[c] = order_up\n","                    method = 'Ordernation_Up'\n","                  else:\n","                    if variation == exec_orddown:\n","                      #ordena em ordem decrescente os elementos\n","                      order_down = -np.sort(-data_exec_x_copy[c])\n","                      data_exec_x_copy[c] = order_down\n","                      method = 'Ordernation_Down'\n","                    else:\n","                      if variation == exec_inver:\n","                        #inverte os elementos\n","                        transp = np.flipud(data_exec_x_copy[c])\n","                        data_exec_x_copy[c] = transp\n","                        method = 'Invertion'\n","                      else:\n","                        if variation == exec_binning:\n","                          #inverte os elementos\n","                          mean_arr = np.mean(data_exec_x_copy[c])\n","                          binn = np.digitize(data_exec_x_copy[c],bins=[mean_arr])\n","                          data_exec_x_copy[c] = binn\n","                          method = 'Binning'\n","                        else:\n","                          if variation == exec_mult_neg:\n","                            #multiplica por -1\n","                            data_exec_x_copy[c] = data_exec_x_copy[c] * -1\n","                            method = 'MultNeg'\n","                          else:\n","                            if variation == exec_mean:\n","                              #mean\n","                              inst =  len(data_exec_x_copy[c])\n","                              data_exec_x_copy[c] = [statistics.mean(data_exec_x_copy[c])]*inst\n","                              method = 'Mean'\n","                            else:\n","                              if variation == exec_std:\n","                                #std\n","                                inst =  len(data_exec_x_copy[c])\n","                                data_exec_x_copy[c] = [statistics.stdev(data_exec_x_copy[c])]*inst\n","                                method = 'Std'\n","                              else:\n","                                if variation == exec_zscore:\n","                                  #zscore\n","                                  data_exec_x_copy[c] = z_score_serie(data_exec_x_copy[c])\n","                                  method = 'Zscore'\n","\n","          if verbose:\n","            print('')\n","            print(method,' of ',c)\n","            print(data_exec_x_copy)\n","          if verbose_graph:\n","            data_exec_x_copy.plot.kde(by=data_exec_x_copy.columns, alpha=0.5,title=str(method+' of '+c))\n","\n","          result_pred = model.predict(data_exec_x_copy) #prediction\n","\n","          if exec_performance == exec_accuracy:\n","            result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=normalize_performance) #accuracy\n","          else:\n","            if exec_performance == exec_auc:\n","              result_accuracy = auc_score(original_outputs, result_pred) #AUC\n","\n","          result_pred = (result_pred == original_outputs) #binarization\n","          str_model_name = 'Clf '+method+' \"'+str(c)+'\"'\n","          list_clf_loop.append(str_model_name)\n","          df_loop_of_models[str_model_name] = result_pred.astype(int)[:]\n","          #myfix#df_loop_of_models_performance = df_loop_of_models_performance.append({'Metodo':str_model_name,'Acuracia':result_accuracy},ignore_index=True,verify_integrity=True)\n","          df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n","\n","    #inset invertion of TWO attributes in loop of models\n","    if number_of_features_variation >= 2:\n","      for _,variation in enumerate(exec_variation_method):\n","        for id1,c1 in enumerate(data_exec_x.columns):\n","          for id2,c2 in enumerate(data_exec_x.columns):\n","            if id2 > id1:\n","              #criando cópia do dado inicial\n","              data_exec_x_copy = data_exec_x.copy()\n","              if variation == exec_permutation:\n","                #trocando posições de cada instância do atributo da vez\n","                random_id = random.sample(range(0,number_of_instances), number_of_instances)\n","                data_exec_x_copy[c1] = data_exec_x_copy[c1].values[random_id]\n","                random_id = random.sample(range(0,number_of_instances), number_of_instances)\n","                data_exec_x_copy[c2] = data_exec_x_copy[c2].values[random_id]\n","                method = 'Permutation'\n","              else:\n","                if variation == exec_noise:\n","                  #aplica ruido a cada instâcia do atributo da vez\n","                  noise = np.random.normal(0, 1, number_of_instances)\n","                  data_exec_x_copy[c1] = data_exec_x_copy[c1] + noise\n","                  noise = np.random.normal(0, 1, number_of_instances)\n","                  data_exec_x_copy[c2] = data_exec_x_copy[c2] + noise\n","                  method = 'Noise'\n","                else:\n","                  if variation == exec_zeros:\n","                    #aplica zeros a cada instância do atributo da vez\n","                    zeros = np.zeros(number_of_instances)\n","                    data_exec_x_copy[c1] = zeros\n","                    data_exec_x_copy[c2] = zeros\n","                    method = 'Zeros'\n","                  else:\n","                    if variation == exec_norm:\n","                      #normaliza os elementos\n","                      norm = np.linalg.norm(data_exec_x_copy[c1])\n","                      normal_array = data_exec_x_copy[c1]/norm\n","                      data_exec_x_copy[c1] = normal_array\n","                      norm = np.linalg.norm(data_exec_x_copy[c2])\n","                      normal_array = data_exec_x_copy[c2]/norm\n","                      data_exec_x_copy[c2] = normal_array\n","                      method = 'Normalization'\n","                    else:\n","                      if variation == exec_ordup:\n","                        #ordena em ordem crescente os elementos\n","                        order_up = np.sort(data_exec_x_copy[c1])\n","                        data_exec_x_copy[c1] = order_up\n","                        order_up = np.sort(data_exec_x_copy[c2])\n","                        data_exec_x_copy[c2] = order_up\n","                        method = 'Ordernation_Up'\n","                      else:\n","                        if variation == exec_orddown:\n","                          #ordena em ordem decrescente os elementos\n","                          order_down = -np.sort(-data_exec_x_copy[c1])\n","                          data_exec_x_copy[c1] = order_down\n","                          order_down = -np.sort(-data_exec_x_copy[c2])\n","                          data_exec_x_copy[c2] = order_down\n","                          method = 'Ordernation_Down'\n","                        else:\n","                          if variation == exec_inver:\n","                            #inverte os elementos\n","                            transp = np.flipud(data_exec_x_copy[c1])\n","                            data_exec_x_copy[c1] = transp\n","                            transp = np.flipud(data_exec_x_copy[c2])\n","                            data_exec_x_copy[c2] = transp\n","                            method = 'Invertion'\n","                          else:\n","                            if variation == exec_binning:\n","                              #inverte os elementos\n","                              mean_arr = np.mean(data_exec_x_copy[c1])\n","                              binn = np.digitize(data_exec_x_copy[c1],bins=[mean_arr])\n","                              data_exec_x_copy[c1] = binn\n","                              mean_arr = np.mean(data_exec_x_copy[c2])\n","                              binn = np.digitize(data_exec_x_copy[c2],bins=[mean_arr])\n","                              data_exec_x_copy[c2] = binn\n","                              method = 'Binning'\n","                            else:\n","                              if variation == exec_mult_neg:\n","                                #multiplica por -1\n","                                data_exec_x_copy[c1] = data_exec_x_copy[c1] * -1\n","                                data_exec_x_copy[c2] = data_exec_x_copy[c2] * -1\n","                                method = 'MultNeg'\n","                              else:\n","                                if variation == exec_mean:\n","                                  #mean\n","                                  inst =  len(data_exec_x_copy[c1])\n","                                  data_exec_x_copy[c1] = [statistics.mean(data_exec_x_copy[c1])]*inst\n","                                  data_exec_x_copy[c2] = [statistics.mean(data_exec_x_copy[c2])]*inst\n","                                  method = 'Mean'\n","                                else:\n","                                  if variation == exec_std:\n","                                    #std\n","                                    inst =  len(data_exec_x_copy[c1])\n","                                    data_exec_x_copy[c1] = [statistics.stdev(data_exec_x_copy[c1])]*inst\n","                                    data_exec_x_copy[c2] = [statistics.stdev(data_exec_x_copy[c2])]*inst\n","                                    method = 'Std'\n","                                  else:\n","                                    if variation == exec_zscore:\n","                                      #zscore\n","                                      data_exec_x_copy[c1] = z_score_serie(data_exec_x_copy[c1])\n","                                      data_exec_x_copy[c2] = z_score_serie(data_exec_x_copy[c2])\n","                                      method = 'Zscore'\n","\n","              str_model_name = 'Clf '+method+' \"'+str(c1)+'\" and \"'+str(c2)+'\"'\n","              if verbose:\n","                print('')\n","                print(str_model_name)\n","                print(data_exec_x_copy)\n","              if verbose_graph:\n","                data_exec_x_copy.plot.kde(by=data_exec_x_copy.columns, alpha=0.5,title=str_model_name)\n","\n","              #executando o modelo com o atributo da vez embaralhado\n","              result_pred = model.predict(data_exec_x_copy) #prediction\n","\n","              if exec_performance == exec_accuracy:\n","                result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=normalize_performance) #accuracy\n","              else:\n","                if exec_performance == exec_auc:\n","                  result_accuracy = auc_score(original_outputs, result_pred) #AUC\n","\n","              result_pred = (result_pred == original_outputs) #binarization\n","              str_model_name = 'Clf '+method+' \"'+str(c1)+'\" and \"'+str(c2)+'\"'\n","              list_clf_loop.append(str_model_name)\n","              df_loop_of_models[str_model_name] = result_pred.astype(int)[:]\n","              #myfix#df_loop_of_models_performance = df_loop_of_models_performance.append({'Metodo':str_model_name,'Acuracia':result_accuracy},ignore_index=True, verify_integrity=True)\n","              df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n","            else:\n","              pass\n","\n","    #inset invertion of Three attributes in loop of models\n","    if number_of_features_variation >= 3:\n","      for _, variation in enumerate(exec_variation_method):\n","        for id1,c1 in enumerate(data_exec_x.columns):\n","          for id2,c2 in enumerate(data_exec_x.columns):\n","            for id3,c3 in enumerate(data_exec_x.columns):\n","              if id3 > id2 and id2 > id1:\n","                #criando cópia do dado inicial\n","                data_exec_x_copy = data_exec_x.copy()\n","                if variation == exec_permutation:\n","                  #trocando posições de cada instância do atributo da vez\n","                  random_id = random.sample(range(0,number_of_instances), number_of_instances)\n","                  data_exec_x_copy[c1] = data_exec_x_copy[c1].values[random_id]\n","                  random_id = random.sample(range(0,number_of_instances), number_of_instances)\n","                  data_exec_x_copy[c2] = data_exec_x_copy[c2].values[random_id]\n","                  random_id = random.sample(range(0,number_of_instances), number_of_instances)\n","                  data_exec_x_copy[c3] = data_exec_x_copy[c3].values[random_id]\n","                  method = 'Permutation'\n","                else:\n","                  if variation == exec_noise:\n","                    #aplica ruido a cada instâcia do atributo da vez\n","                    noise = np.random.normal(0, 1, number_of_instances)\n","                    data_exec_x_copy[c1] = data_exec_x_copy[c1] + noise\n","                    noise = np.random.normal(0, 1, number_of_instances)\n","                    data_exec_x_copy[c2] = data_exec_x_copy[c2] + noise\n","                    noise = np.random.normal(0, 1, number_of_instances)\n","                    data_exec_x_copy[c3] = data_exec_x_copy[c3] + noise\n","                    method = 'Noise'\n","                  else:\n","                    if variation == exec_zeros:\n","                      #aplica zeros a cada instância do atributo da vez\n","                      zeros = np.zeros(number_of_instances)\n","                      data_exec_x_copy[c1] = zeros\n","                      data_exec_x_copy[c2] = zeros\n","                      data_exec_x_copy[c3] = zeros\n","                      method = 'Zeros'\n","                    else:\n","                      if variation == exec_norm:\n","                        #normaliza os elementos\n","                        norm = np.linalg.norm(data_exec_x_copy[c1])\n","                        normal_array = data_exec_x_copy[c1]/norm\n","                        data_exec_x_copy[c1] = normal_array\n","                        norm = np.linalg.norm(data_exec_x_copy[c2])\n","                        normal_array = data_exec_x_copy[c2]/norm\n","                        data_exec_x_copy[c2] = normal_array\n","                        normal_array = data_exec_x_copy[c3]/norm\n","                        data_exec_x_copy[c3] = normal_array\n","                        method = 'Normalization'\n","                      else:\n","                        if variation == exec_ordup:\n","                          #ordena em ordem crescente os elementos\n","                          order_up = np.sort(data_exec_x_copy[c1])\n","                          data_exec_x_copy[c1] = order_up\n","                          order_up = np.sort(data_exec_x_copy[c2])\n","                          data_exec_x_copy[c2] = order_up\n","                          order_up = np.sort(data_exec_x_copy[c3])\n","                          data_exec_x_copy[c3] = order_up\n","                          method = 'Ordernation_Up'\n","                        else:\n","                          if variation == exec_orddown:\n","                            #ordena em ordem decrescente os elementos\n","                            order_down = -np.sort(-data_exec_x_copy[c1])\n","                            data_exec_x_copy[c1] = order_down\n","                            order_down = -np.sort(-data_exec_x_copy[c2])\n","                            data_exec_x_copy[c2] = order_down\n","                            order_down = -np.sort(-data_exec_x_copy[c3])\n","                            data_exec_x_copy[c3] = order_down\n","                            method = 'Ordernation_Down'\n","                          else:\n","                            if variation == exec_inver:\n","                              #inverte os elementos\n","                              transp = np.flipud(data_exec_x_copy[c1])\n","                              data_exec_x_copy[c1] = transp\n","                              transp = np.flipud(data_exec_x_copy[c2])\n","                              data_exec_x_copy[c2] = transp\n","                              transp = np.flipud(data_exec_x_copy[c3])\n","                              data_exec_x_copy[c3] = transp\n","                              method = 'Invertion'\n","                            else:\n","                              if variation == exec_binning:\n","                                #inverte os elementos\n","                                mean_arr = np.mean(data_exec_x_copy[c1])\n","                                binn = np.digitize(data_exec_x_copy[c1],bins=[mean_arr])\n","                                data_exec_x_copy[c1] = binn\n","                                mean_arr = np.mean(data_exec_x_copy[c2])\n","                                binn = np.digitize(data_exec_x_copy[c2],bins=[mean_arr])\n","                                data_exec_x_copy[c2] = binn\n","                                mean_arr = np.mean(data_exec_x_copy[c3])\n","                                binn = np.digitize(data_exec_x_copy[c3],bins=[mean_arr])\n","                                data_exec_x_copy[c3] = binn\n","                                method = 'Binning'\n","                              else:\n","                                if variation == exec_mult_neg:\n","                                  #multiplica por -1\n","                                  data_exec_x_copy[c1] = data_exec_x_copy[c1] * -1\n","                                  data_exec_x_copy[c2] = data_exec_x_copy[c2] * -1\n","                                  data_exec_x_copy[c3] = data_exec_x_copy[c3] * -1\n","                                  method = 'MultNeg'\n","                                else:\n","                                  if variation == exec_mean:\n","                                    #mean\n","                                    inst =  len(data_exec_x_copy[c1])\n","                                    data_exec_x_copy[c1] = [statistics.mean(data_exec_x_copy[c1])]*inst\n","                                    data_exec_x_copy[c2] = [statistics.mean(data_exec_x_copy[c2])]*inst\n","                                    data_exec_x_copy[c3] = [statistics.mean(data_exec_x_copy[c3])]*inst\n","                                    method = 'Mean'\n","                                  else:\n","                                    if variation == exec_std:\n","                                      #std\n","                                      inst =  len(data_exec_x_copy[c1])\n","                                      data_exec_x_copy[c1] = [statistics.stdev(data_exec_x_copy[c1])]*inst\n","                                      data_exec_x_copy[c2] = [statistics.stdev(data_exec_x_copy[c2])]*inst\n","                                      data_exec_x_copy[c3] = [statistics.stdev(data_exec_x_copy[c3])]*inst\n","                                      method = 'Std'\n","                                    else:\n","                                      if variation == exec_zscore:\n","                                        #zscore\n","                                        data_exec_x_copy[c1] = z_score_serie(data_exec_x_copy[c1])\n","                                        data_exec_x_copy[c2] = z_score_serie(data_exec_x_copy[c2])\n","                                        data_exec_x_copy[c3] = z_score_serie(data_exec_x_copy[c3])\n","                                        method = 'Zscore'\n","\n","                  \n","                str_model_name = 'Clf '+method+' \"'+str(c1)+'\" and \"'+str(c2)+'\" and \"'+str(c3)+'\"'\n","                if verbose:\n","                  print('')\n","                  print(str_model_name)\n","                  print(data_exec_x_copy)\n","                if verbose_graph:\n","                  data_exec_x_copy.plot.kde(by=data_exec_x_copy.columns, alpha=0.5,title=str_model_name)\n","\n","                \n","                result_pred = model.predict(data_exec_x_copy) #prediction\n","\n","                if exec_performance == exec_accuracy:\n","                  result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=normalize_performance) #accuracy\n","                else:\n","                  if exec_performance == exec_auc:\n","                    result_accuracy = auc_score(original_outputs, result_pred) #AUC\n","\n","                result_pred = (result_pred == original_outputs) #binarization\n","                list_clf_loop.append(str_model_name)\n","                df_loop_of_models[str_model_name] = result_pred.astype(int)[:]\n","                #myfix#df_loop_of_models_performance = df_loop_of_models_performance.append({'Metodo':str_model_name,'Acuracia':result_accuracy},ignore_index=True, verify_integrity=True)\n","                df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n","              else:\n","                pass\n","\n","    #inset invertion of Four attributes in loop of models\n","    if number_of_features_variation == 4:\n","      for _, variation in enumerate(exec_variation_method):\n","        for id1,c1 in enumerate(data_exec_x.columns):\n","          for id2,c2 in enumerate(data_exec_x.columns):\n","            for id3,c3 in enumerate(data_exec_x.columns):\n","              for id4,c4 in enumerate(data_exec_x.columns):\n","                if id4 > id3 and id3 > id2 and id2 > id1:\n","                  #criando cópia do dado inicial\n","                  data_exec_x_copy = data_exec_x.copy()\n","                  if variation == exec_permutation:\n","                    #trocando posições de cada instância do atributo da vez\n","                    random_id = random.sample(range(0,number_of_instances), number_of_instances)\n","                    data_exec_x_copy[c1] = data_exec_x_copy[c1].values[random_id]\n","                    random_id = random.sample(range(0,number_of_instances), number_of_instances)\n","                    data_exec_x_copy[c2] = data_exec_x_copy[c2].values[random_id]\n","                    random_id = random.sample(range(0,number_of_instances), number_of_instances)\n","                    data_exec_x_copy[c3] = data_exec_x_copy[c3].values[random_id]\n","                    random_id = random.sample(range(0,number_of_instances), number_of_instances)\n","                    data_exec_x_copy[c4] = data_exec_x_copy[c4].values[random_id]\n","                    method = 'Permutation'\n","                  else:\n","                    if variation == exec_noise:\n","                      #aplica ruido a cada instâcia do atributo da vez\n","                      noise = np.random.normal(0, 1, number_of_instances)\n","                      data_exec_x_copy[c1] = data_exec_x_copy[c1] + noise\n","                      noise = np.random.normal(0, 1, number_of_instances)\n","                      data_exec_x_copy[c2] = data_exec_x_copy[c2] + noise\n","                      noise = np.random.normal(0, 1, number_of_instances)\n","                      data_exec_x_copy[c3] = data_exec_x_copy[c3] + noise\n","                      noise = np.random.normal(0, 1, number_of_instances)\n","                      data_exec_x_copy[c4] = data_exec_x_copy[c4] + noise\n","                      method = 'Noise'\n","                    else:\n","                      if variation == exec_zeros:\n","                        #aplica zeros a cada instância do atributo da vez\n","                        zeros = np.zeros(number_of_instances)\n","                        data_exec_x_copy[c1] = zeros\n","                        data_exec_x_copy[c2] = zeros\n","                        data_exec_x_copy[c3] = zeros\n","                        data_exec_x_copy[c4] = zeros\n","                        method = 'Zeros'\n","                      else:\n","                        if variation == exec_norm:\n","                          #normaliza os elementos\n","                          norm = np.linalg.norm(data_exec_x_copy[c1])\n","                          normal_array = data_exec_x_copy[c1]/norm\n","                          data_exec_x_copy[c1] = normal_array\n","                          norm = np.linalg.norm(data_exec_x_copy[c2])\n","                          normal_array = data_exec_x_copy[c2]/norm\n","                          data_exec_x_copy[c2] = normal_array\n","                          normal_array = data_exec_x_copy[c3]/norm\n","                          data_exec_x_copy[c3] = normal_array\n","                          normal_array = data_exec_x_copy[c4]/norm\n","                          data_exec_x_copy[c4] = normal_array\n","                          method = 'Normalization'\n","                        else:\n","                          if variation == exec_ordup:\n","                            #ordena em ordem crescente os elementos\n","                            order_up = np.sort(data_exec_x_copy[c1])\n","                            data_exec_x_copy[c1] = order_up\n","                            order_up = np.sort(data_exec_x_copy[c2])\n","                            data_exec_x_copy[c2] = order_up\n","                            order_up = np.sort(data_exec_x_copy[c3])\n","                            data_exec_x_copy[c3] = order_up\n","                            order_up = np.sort(data_exec_x_copy[c4])\n","                            data_exec_x_copy[c4] = order_up\n","                            method = 'Ordernation_Up'\n","                          else:\n","                            if variation == exec_orddown:\n","                              #ordena em ordem decrescente os elementos\n","                              order_down = -np.sort(-data_exec_x_copy[c1])\n","                              data_exec_x_copy[c1] = order_down\n","                              order_down = -np.sort(-data_exec_x_copy[c2])\n","                              data_exec_x_copy[c2] = order_down\n","                              order_down = -np.sort(-data_exec_x_copy[c3])\n","                              data_exec_x_copy[c3] = order_down\n","                              order_down = -np.sort(-data_exec_x_copy[c4])\n","                              data_exec_x_copy[c4] = order_down\n","                              method = 'Ordernation_Down'\n","                            else:\n","                              if variation == exec_inver:\n","                                #inverte os elementos\n","                                transp = np.flipud(data_exec_x_copy[c1])\n","                                data_exec_x_copy[c1] = transp\n","                                transp = np.flipud(data_exec_x_copy[c2])\n","                                data_exec_x_copy[c2] = transp\n","                                transp = np.flipud(data_exec_x_copy[c3])\n","                                data_exec_x_copy[c3] = transp\n","                                transp = np.flipud(data_exec_x_copy[c4])\n","                                data_exec_x_copy[c4] = transp\n","                                method = 'Invertion'\n","                              else:\n","                                if variation == exec_binning:\n","                                  #inverte os elementos\n","                                  mean_arr = np.mean(data_exec_x_copy[c1])\n","                                  binn = np.digitize(data_exec_x_copy[c1],bins=[mean_arr])\n","                                  data_exec_x_copy[c1] = binn\n","                                  mean_arr = np.mean(data_exec_x_copy[c2])\n","                                  binn = np.digitize(data_exec_x_copy[c2],bins=[mean_arr])\n","                                  data_exec_x_copy[c2] = binn\n","                                  mean_arr = np.mean(data_exec_x_copy[c3])\n","                                  binn = np.digitize(data_exec_x_copy[c3],bins=[mean_arr])\n","                                  data_exec_x_copy[c3] = binn\n","                                  mean_arr = np.mean(data_exec_x_copy[c4])\n","                                  binn = np.digitize(data_exec_x_copy[c4],bins=[mean_arr])\n","                                  data_exec_x_copy[c4] = binn\n","                                  method = 'Binning'\n","                                else:\n","                                  if variation == exec_mult_neg:\n","                                    #multiplica por -1\n","                                    data_exec_x_copy[c1] = data_exec_x_copy[c1] * -1\n","                                    data_exec_x_copy[c2] = data_exec_x_copy[c2] * -1\n","                                    data_exec_x_copy[c3] = data_exec_x_copy[c3] * -1\n","                                    data_exec_x_copy[c4] = data_exec_x_copy[c4] * -1\n","                                    method = 'MultNeg'\n","                                  else:\n","                                    if variation == exec_mean:\n","                                      #mean\n","                                      inst =  len(data_exec_x_copy[c1])\n","                                      data_exec_x_copy[c1] = [statistics.mean(data_exec_x_copy[c1])]*inst\n","                                      data_exec_x_copy[c2] = [statistics.mean(data_exec_x_copy[c2])]*inst\n","                                      data_exec_x_copy[c3] = [statistics.mean(data_exec_x_copy[c3])]*inst\n","                                      data_exec_x_copy[c4] = [statistics.mean(data_exec_x_copy[c4])]*inst\n","                                      method = 'Mean'\n","                                    else:\n","                                      if variation == exec_std:\n","                                        #std\n","                                        inst =  len(data_exec_x_copy[c1])\n","                                        data_exec_x_copy[c1] = [statistics.stdev(data_exec_x_copy[c1])]*inst\n","                                        data_exec_x_copy[c2] = [statistics.stdev(data_exec_x_copy[c2])]*inst\n","                                        data_exec_x_copy[c3] = [statistics.stdev(data_exec_x_copy[c3])]*inst\n","                                        data_exec_x_copy[c4] = [statistics.stdev(data_exec_x_copy[c4])]*inst\n","                                        method = 'Std'\n","                                      else:\n","                                        if variation == exec_zscore:\n","                                          #zscore\n","                                          data_exec_x_copy[c1] = z_score_serie(data_exec_x_copy[c1])\n","                                          data_exec_x_copy[c2] = z_score_serie(data_exec_x_copy[c2])\n","                                          data_exec_x_copy[c3] = z_score_serie(data_exec_x_copy[c3])\n","                                          data_exec_x_copy[c4] = z_score_serie(data_exec_x_copy[c4])\n","                                          method = 'Zscore'\n","                  \n","                  str_model_name = 'Clf '+method+' \"'+str(c1)+'\" and \"'+str(c2)+'\" and \"'+str(c3)+'\" and \"'+str(c4)+'\"'\n","                  if verbose:\n","                    print('')\n","                    print(str_model_name)\n","                    print(data_exec_x_copy)\n","                  if verbose_graph:\n","                    data_exec_x_copy.plot.kde(by=data_exec_x_copy.columns, alpha=0.5,title=str_model_name)\n","\n","                  result_pred = model.predict(data_exec_x_copy) #prediction\n","\n","                  if exec_performance == exec_accuracy:\n","                    result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=normalize_performance) #accuracy\n","                  else:\n","                    if exec_performance == exec_auc:\n","                      result_accuracy = auc_score(original_outputs, result_pred) #AUC\n","\n","                  result_pred = (result_pred == original_outputs) #binarization\n","                  list_clf_loop.append(str_model_name)\n","                  df_loop_of_models[str_model_name] = result_pred.astype(int)[:]\n","                  #myfix#df_loop_of_models_performance = df_loop_of_models_performance.append({'Metodo':str_model_name,'Acuracia':result_accuracy},ignore_index=True, verify_integrity=True)\n","                  df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n","                else:\n","                  pass\n","  else:\n","    if exec_proposal == proposal_1_pool:\n","      \n","      model_copy = copy.deepcopy(model)\n","\n","      if include_original_clf_data_pool:\n","        original_outputs = model_copy.predict(X_test)\n","        \n","        if exec_performance == exec_accuracy:\n","          result_accuracy = accuracy_score(y_true = original_outputs, y_pred = original_outputs, normalize=normalize_performance) #accuracy\n","        else:\n","          if exec_performance == exec_auc:\n","            result_accuracy = auc_score(original_outputs, original_outputs) #AUC\n","        \n","        result_pred = (original_outputs == original_outputs) #binarization\n","        \n","\n","        str_model_name = 'Original model'\n","        list_clf_pool.append(str_model_name)\n","        df_loop_of_models[str_model_name] = result_pred.astype(int)[:]\n","        #myfix#df_loop_of_models_performance = df_loop_of_models_performance.append({'Metodo':str_model_name,'Acuracia':result_accuracy},ignore_index=True)\n","        df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n","        if verbose:\n","          print('')\n","          print(str_model_name)\n","          print(X_test)\n","      \n","      ps = powerSetLimited(data_exec_x.columns, number_of_features_deletion) #powerset of all features\n","      \n","      for _, ps_c in enumerate(ps):\n","        data_train_x_copy = X_train.copy()\n","        data_test_x_copy = X_test.copy()\n","        for _, c in enumerate(ps_c):\n","          flag_none = True\n","          #remove feature c\n","          data_train_x_copy = data_train_x_copy.drop(c, axis='columns')\n","          data_test_x_copy = data_test_x_copy.drop(c, axis='columns')\n","\n","        if len(data_train_x_copy.columns) == 0:\n","          break\n","\n","        #train new model\n","        model_copy.fit(data_train_x_copy, y_train)\n","\n","        result_pred = model_copy.predict(data_test_x_copy)\n","        if exec_performance == exec_accuracy:\n","          result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=normalize_performance) #accuracy\n","        else:\n","          if exec_performance == exec_auc:\n","            result_accuracy = auc_score(original_outputs, result_pred) #AUC\n","\n","        result_pred = (result_pred == original_outputs) #binarization\n","          \n","        str_model_name = 'Clf feature elimination: '\n","        for _, i in enumerate(ps_c):\n","          str_model_name = str_model_name + '\"'+str(i)+'\" '\n","        list_clf_pool.append(str_model_name)\n","        df_loop_of_models[str_model_name] = result_pred.astype(int)[:]\n","        #myfix#df_loop_of_models_performance = df_loop_of_models_performance.append({'Metodo':str_model_name,'Acuracia':result_accuracy}, ignore_index=True)\n","        df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n","        if verbose:\n","          print('')\n","          print(str_model_name)\n","          print(data_test_x_copy)\n","\n","  #add V in index\n","  df_loop_of_models = df_loop_of_models.set_index('V' + str(i) for i in df_loop_of_models.index.values)\n","\n","  if verbose:\n","    print('Resume Loop of model')\n","    print(df_loop_of_models.transpose())\n","    print()\n","    print('Resume Loop of model accuracy')\n","    print(df_loop_of_models_performance)\n","\n","  df = df_loop_of_models.transpose()\n","  df.to_csv(path_content+path_irt+\"/tabela_base_para_executar_irt.csv\")\n","  if download_files:\n","    files.download(path_content+path_irt+\"/tabela_base_para_executar_irt.csv\") \n","\n","  df = df_loop_of_models_performance\n","  df.to_csv(path_content+path_irt+\"/tabela_base_para_executar_irt_accuracy.csv\",index=False)\n","  if download_files:\n","    files.download(path_content+path_irt+\"/tabela_base_para_executar_irt_accuracy.csv\")\n","\n","  return  df_loop_of_models, df_loop_of_models_performance\n","\n","def run_irt(datasetName):\n","\n","  global path_dataset\n","\n","  %rm -rf $path_content$path_irt'/irt_item_param.csv'\n","  %rm -rf $path_content$path_irt'/irt_item_param_new.csv'\n","  %rm -rf $path_content$path_irt'/OutExecution/theta_list.csv'\n","  %rm -rf $path_content$path_irt'/OutExecution/score_total.csv'\n","\n","  !python decodIRT_MLtIRT.py -dir $path_irt -respMatrix $path_content$path_irt'/tabela_base_para_executar_irt.csv'\n","\n","  url = path_content+path_irt+'/irt_item_param.csv'\n","  result_irt = pd.read_csv(url)\n","  if download_files:\n","    files.download(url) \n","  \n","  result_irt_new = result_irt.copy()\n","\n","  #save parameters of item by datset\n","  result_irt_dataset = result_irt.copy()\n","  result_irt_dataset.to_csv(path_content+path_irt+path_dataset+'/irt_item_param_'+datasetName+'.csv',index=False)\n","  if download_files:\n","    files.download(path_content+path_irt+path_dataset+'/irt_item_param_'+datasetName+'.csv')\n","\n","  if irt_divine == False:\n","    result_irt_new['Adivinhacao'] = [0]*len(result_irt_new['Adivinhacao']) #anula os valores de adivinhação\n","  if irt_difficulty == False:\n","    result_irt_new['Dificuldade'] = [0]*len(result_irt_new['Dificuldade']) #anula os valores de dificuldade\n","  if irt_discriminate == False:\n","    result_irt_new['Discriminacao'] = [0]*len(result_irt_new['Discriminacao']) #anula os valores de Discriminacao\n","\n","  result_irt_new.to_csv(path_content+path_irt+'/irt_item_param_new.csv',index=False)\n","\n","  !python decodIRT_analysis.py -dir $path_irt -nameData OutExecution -respMatrix $path_content$path_irt'/tabela_base_para_executar_irt.csv' -IRTparam $path_content$path_irt'/irt_item_param_new.csv' -accur $path_content$path_irt'/tabela_base_para_executar_irt_accuracy.csv' -scoreAll -save $irt_method -missing\n","\n","  \n","  %cat IRT_param_freq.txt\n","  %cp IRT_param_freq.txt $path_content$path_irt$path_dataset'/IRT_param_freq_'$datasetName'.txt'\n","  return result_irt_new, result_irt\n","  \n","def run_calc(name_of_features_x,datasetName):\n","  global path_dataset\n","\n","  if exec_base_irt_score == exec_theta:\n","    url = path_content+path_irt+'/OutExecution/theta_list.csv'\n","    name_col = 'Theta'\n","  else:\n","    if exec_base_irt_score == exec_trueScore:\n","      url = path_content+path_irt+'/OutExecution/score_total.csv'\n","      name_col = 'Score'\n","  \n","  rank_theta = pd.read_csv(url)\n","\n","\n","  if download_files:\n","    files.download(url)\n","  rank_theta = rank_theta.sort_values(name_col,ascending=True)\n","  \n","  # if exec_proposal == proposal_1_pool:\n","  #   k = number_of_features*number_of_features_deletion*4\n","  # else:\n","  #   if exec_proposal == proposal_2_loop:\n","  #     k = number_of_features*len(exec_variation_method)*number_of_features_variation\n","  \n","  \n","  #rank_theta.plot.barh(x='Clf',y=name_col,figsize = (15,k),color='green')\n","  rank_theta = rank_theta.set_index(keys='Clf')\n","\n","  if exec_proposal == proposal_2_loop:\n","    rank_theta_loop = rank_theta.sort_values(by=name_col, ascending=True)\n","\n","    df_rank_final = pd.DataFrame(index=name_of_features_x, columns=[str('Final '+name_col)])\n","    \n","    for _, feature in enumerate(name_of_features_x):\n","      if exec_calc_theta == theta_sum:\n","        df_rank_final.loc[feature,str('Final '+name_col)] = sum(rank_theta_loop.filter(like='\"'+feature+'\"', axis='index')[name_col])\n","      else:\n","        if exec_calc_theta == theta_min:\n","          df_rank_final.loc[feature,str('Final '+name_col)] = min(rank_theta_loop.filter(like='\"'+feature+'\"', axis='index')[name_col])\n","        else:\n","          if exec_calc_theta == theta_mean:\n","            df_rank_final.loc[feature,str('Final '+name_col)] = statistics.mean(rank_theta_loop.filter(like='\"'+feature+'\"', axis='index')[name_col])\n","\n","    df_rank_final = df_rank_final.sort_values(by=str('Final '+name_col), ascending=True)\n","    df_rank_final\n","  else:\n","    if exec_proposal == proposal_1_pool:\n","\n","      rank_theta_pool = rank_theta.sort_values(by=name_col, ascending=True)\n","\n","      df_rank_final = pd.DataFrame(index=name_of_features_x, columns=[str('Final '+name_col)])\n","      \n","      for _, feature in enumerate(name_of_features_x):\n","        if exec_calc_theta == theta_sum:\n","          df_rank_final.loc[feature,str('Final '+name_col)] = sum(rank_theta_pool.filter(like=feature, axis='index')[name_col])\n","        else:\n","          if exec_calc_theta == theta_min:\n","            df_rank_final.loc[feature,str('Final '+name_col)] = min(rank_theta_pool.filter(like=feature, axis='index')[name_col])\n","          else:\n","            if exec_calc_theta == theta_mean:\n","              df_rank_final.loc[feature,str('Final '+name_col)] = statistics.mean(rank_theta_pool.filter(like=feature, axis='index')[name_col])\n","\n","      df_rank_final = df_rank_final.sort_values(by=str('Final '+name_col), ascending=True)\n","\n","\n","  \n","  df_rank_final.to_csv(path_content+path_irt+path_dataset+'/rank_final_'+datasetName+'.csv',index=True)\n","  return df_rank_final\n","\n","def explainRankByEXirt(model, X_train, X_test, y_train, y_test,datasetName):\n","  global path_dataset\n","\n","  path_dataset = '/'+datasetName\n","  dirByDataset(path_dataset)\n","\n","  if(exec_in == exec_test):\n","    data_exec_x = X_test\n","    data_exec_y = y_test \n","  else:\n","    data_exec_x = X_train\n","    data_exec_y = y_train\n","\n","  \n","  N = 500\n","  if len(data_exec_y) > N:\n","    data_sample = data_exec_x\n","    data_sample['class'] = data_exec_y\n","\n","    #stratifier sampler\n","    data_sample = data_sample.groupby('class', group_keys=False).apply(lambda x: x.sample(int(np.rint(N*len(x)/len(data_sample))))).sample(frac=1).reset_index(drop=True)\n","    \n","    data_exec_y = data_sample['class']\n","    data_sample = data_sample.drop(labels='class', axis=1)\n","    data_exec_x = data_sample\n","\n","  a, b = run_prepare(model, data_exec_x, data_exec_y, X_train, X_test, y_train, y_test)\n","  \n","  rirt_new, rirt = run_irt(datasetName)\n","  \n","  rank = run_calc(X_train.columns,datasetName)\n","  \n","  return list(rank.index), rank"]},{"cell_type":"markdown","source":["## Load data and Pre-process"],"metadata":{"id":"nvKrH0aUlvC-"}},{"cell_type":"code","source":["def normalize(df):\n","    # copy the dataframe\n","    df_norm = df.copy()\n","    # apply min-max scaling\n","    for column in df_norm.columns:\n","        if(len(df_norm[column].unique()) > 1): #fix NaN generation\n","          df_norm[column] = (df_norm[column] - df_norm[column].min()) / (df_norm[column].max() - df_norm[column].min())\n","        else:\n","          df_norm[column] = 0\n","    return df_norm"],"metadata":{"id":"2YGB9snVsqaZ","executionInfo":{"status":"ok","timestamp":1673101354620,"user_tz":180,"elapsed":1,"user":{"displayName":"José Ribeiro","userId":"10789669540889156464"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#Select dataset name by openml link https://www.openml.org/search?sort=date"],"metadata":{"id":"hSjFdmrjp9ui"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load dataset by OpenML\n","\n","dataset_name = \"pc1\"\n","dataset = openml.datasets.get_dataset(dataset_name)\n","X, Y, categorical_indicator, attribute_names = dataset.get_data(\n","                  dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n","\n","#Preprocess Y and X numerics\n","\n","if (Y.dtype != 'numeric'):\n","  Y = Y.astype(int)\n","\n","for i,c in enumerate(X.columns):\n","  if (X[c].dtype != 'float64'):\n","    X = X.astype(float)\n","\n","#Normalization\n","X = normalize(X)\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify=Y) # 70% training and 30% test\n","\n"],"metadata":{"id":"oYts5cLPlzTE","executionInfo":{"status":"ok","timestamp":1673101366555,"user_tz":180,"elapsed":11511,"user":{"displayName":"José Ribeiro","userId":"10789669540889156464"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Creation and prediction model"],"metadata":{"id":"mtvHAgCLtPXm"}},{"cell_type":"code","source":["model = RandomForestClassifier(200)\n","model.fit(X_train, y_train)\n","prediction = model.predict(X_test)"],"metadata":{"id":"MgvqLmsum_nC","executionInfo":{"status":"ok","timestamp":1673101369336,"user_tz":180,"elapsed":1413,"user":{"displayName":"José Ribeiro","userId":"10789669540889156464"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Global explanation rank"],"metadata":{"id":"_NNGxuw4ucIB"}},{"cell_type":"code","source":["global_explanation_attributes, global_explanation_attributes_scores = explainRankByEXirt(model, X_train, X_test, y_train, y_test,dataset_name+'_rf')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":681},"id":"T8OEPD8bue2F","executionInfo":{"status":"ok","timestamp":1673101921517,"user_tz":180,"elapsed":119133,"user":{"displayName":"José Ribeiro","userId":"10789669540889156464"}},"outputId":"080de370-9f08-46fc-afb3-a0dbf037cb86"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/content/out_fig/pc1_rf’: File exists\n","mkdir: cannot create directory ‘/content/out_csv/pc1_rf’: File exists\n","mkdir: cannot create directory ‘/content/out_model/pc1_rf’: File exists\n","mkdir: cannot create directory ‘/content/out_irt/pc1_rf’: File exists\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_7c116aa5-7ac0-4f16-a2bc-08f1db233322\", \"tabela_base_para_executar_irt.csv\", 327068)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_e016f669-a394-46c5-a7de-281122fd7650\", \"tabela_base_para_executar_irt_accuracy.csv\", 23234)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Calculando os parametros do IRT para o dataset:  /content/out_irt/tabela_base_para_executar_irt.csv\n","R[write to console]: Warning message:\n","\n","R[write to console]: In tpm(read.csv(file = \"tmp_irt_teste.csv\"), IRT.param = TRUE) :\n","R[write to console]: \n"," \n","R[write to console]:  Hessian matrix at convergence contains infinite or missing values; unstable solution.\n","\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_d087b972-05de-4869-97f2-d8e7ebc0eae3\", \"irt_item_param.csv\", 7814)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_a99e5482-0ebf-4c79-a164-d2c5d3033964\", \"irt_item_param_pc1_rf.csv\", 7824)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["As frequencias dos parametros de item foram salvas \\o/\n","\n","/usr/local/lib/python3.8/dist-packages/scipy/optimize/optimize.py:2046: RuntimeWarning: invalid value encountered in double_scalars\n","  p = (xf - fulc) * q - (xf - nfc) * r\n","/usr/local/lib/python3.8/dist-packages/scipy/optimize/optimize.py:2047: RuntimeWarning: invalid value encountered in double_scalars\n","  q = 2.0 * (q - r)\n","Todos os valores de Theta foram salvos \\o/\n","No handles with labels found to put in legend.\n","\n","Os scores dos classificadores para todos os datasets foram salvos \\o/\n","\n","Porcentagem de itens com valores altos do parametro Discriminacao\n","Dataset \t\t\t\t Percentual de itens\n","OutExecution                                    98%\n","------------------------------------------------------------\n","Porcentagem de itens com valores altos do parametro Dificuldade\n","Dataset \t\t\t\t Percentual de itens\n","OutExecution                                     1%\n","------------------------------------------------------------\n","Porcentagem de itens com valores altos do parametro Advinhacao\n","Dataset \t\t\t\t Percentual de itens\n","OutExecution                                     2%\n","------------------------------------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_457b3204-449d-418d-9681-533edf33b2ed\", \"score_total.csv\", 25680)"]},"metadata":{}}]},{"cell_type":"code","source":["global_explanation_attributes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pd-KdbaMo4Zy","executionInfo":{"status":"ok","timestamp":1673101921517,"user_tz":180,"elapsed":11,"user":{"displayName":"José Ribeiro","userId":"10789669540889156464"}},"outputId":"6e4809a6-eaa4-417d-f806-cf55cc2a154d"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['lOComment',\n"," 'lOBlank',\n"," 'uniq_Op',\n"," 'I',\n"," 'uniq_Opnd',\n"," 'locCodeAndComment',\n"," 'N',\n"," 'lOCode',\n"," 'V',\n"," 'T',\n"," 'total_Op',\n"," 'total_Opnd',\n"," 'E',\n"," 'B',\n"," 'v(g)',\n"," 'loc',\n"," 'iv(G)',\n"," 'ev(g)',\n"," 'D',\n"," 'L',\n"," 'branchCount']"]},"metadata":{},"execution_count":12}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}